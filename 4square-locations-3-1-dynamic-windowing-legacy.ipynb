{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 4 Part 2 - Dynamic Windowing\n",
    "\n",
    "This notebook contains the first tests that were executed when working with the dynamic windowing.\n",
    "Many different models were trained.\n",
    "The code is deprecated and uncommented but can be used to see how the different models perform in comparison."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "\n",
    "\"timeseries_dataset_from_array\" is a function that is not part of the used tf version but is required to transform the data, thus it is manually copied here and modified slightly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model_helper.ipynb\n"
     ]
    }
   ],
   "source": [
    "from model_helper import ModelHelper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The usual reading of the csv and setting of the vocabulary size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   location_id  user_id  clock_sin  clock_cos   day_sin   day_cos  month_sin  \\\n0            0      470  -1.000000   0.000654  0.587785  0.809017   0.866025   \n1            1      979  -0.999998   0.001818  0.587785  0.809017   0.866025   \n2            2       69  -0.999945   0.010472  0.587785  0.809017   0.866025   \n3            3      395  -0.999931   0.011708  0.587785  0.809017   0.866025   \n4            0       87  -0.999914   0.013090  0.587785  0.809017   0.866025   \n5            4      484  -0.999848   0.017452  0.587785  0.809017   0.866025   \n6            3      642  -0.999796   0.020215  0.587785  0.809017   0.866025   \n7            5      292  -0.999790   0.020506  0.587785  0.809017   0.866025   \n8            1      428  -0.999622   0.027485  0.587785  0.809017   0.866025   \n9            1      877  -0.999620   0.027558  0.587785  0.809017   0.866025   \n\n   month_cos  week_day_sin  week_day_cos  \n0       -0.5      0.781831       0.62349  \n1       -0.5      0.781831       0.62349  \n2       -0.5      0.781831       0.62349  \n3       -0.5      0.781831       0.62349  \n4       -0.5      0.781831       0.62349  \n5       -0.5      0.781831       0.62349  \n6       -0.5      0.781831       0.62349  \n7       -0.5      0.781831       0.62349  \n8       -0.5      0.781831       0.62349  \n9       -0.5      0.781831       0.62349  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location_id</th>\n      <th>user_id</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>470</td>\n      <td>-1.000000</td>\n      <td>0.000654</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>979</td>\n      <td>-0.999998</td>\n      <td>0.001818</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>69</td>\n      <td>-0.999945</td>\n      <td>0.010472</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>395</td>\n      <td>-0.999931</td>\n      <td>0.011708</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>87</td>\n      <td>-0.999914</td>\n      <td>0.013090</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>484</td>\n      <td>-0.999848</td>\n      <td>0.017452</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>642</td>\n      <td>-0.999796</td>\n      <td>0.020215</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5</td>\n      <td>292</td>\n      <td>-0.999790</td>\n      <td>0.020506</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>428</td>\n      <td>-0.999622</td>\n      <td>0.027485</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>877</td>\n      <td>-0.999620</td>\n      <td>0.027558</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./4square/processed_transformed_locations.csv\")\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "141"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = df.location_id\n",
    "vocab_size = locations.nunique()\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "mh = ModelHelper(df, 17)\n",
    "mh.set_client_column_name('user_id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate location sequences."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "141"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.set_target_column_name('location_id')\n",
    "mh.set_vocab_size()\n",
    "mh.vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelHelper' object has no attribute 'users_locations'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11776\\890871596.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit_concat_user_df\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mmh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf_train\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\model_helper.ipynb\u001B[0m in \u001B[0;36msplit_concat_user_df\u001B[1;34m(self)\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ModelHelper' object has no attribute 'users_locations'"
     ]
    }
   ],
   "source": [
    "mh.split_concat_user_df()\n",
    "mh.df_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The WindowGenerator class gets the train/val/test data as well as several other parameters:\n",
    "* input_width - defines the length of the input as part of the window\n",
    "* label_width - defines the length of the label (prediction target) as part of the window, can be used to predict multiple time steps in the future\n",
    "* shift - offsets the label by the respective number of (time) steps\n",
    "* label_columns - the columns used for the prediction\n",
    "\n",
    "Examples found below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exemplary window, output shows the indices."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 17\nInput indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\nLabel indices: [16]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = WindowGenerator(input_width=16, label_width=1, shift=1,\n",
    "                     label_columns=['cat_id'])\n",
    "w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 'split_window' function does the slicing of the dataset according to the window indices."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (batch, time, features)\n",
      "Window shape: (3, 17, 9)\n",
      "Inputs shape: (3, 16, 9)\n",
      "Labels shape: (3, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(mh.df_train[:w.total_window_size]),\n",
    "                           np.array(mh.df_train[100:100+w.total_window_size]),\n",
    "                           np.array(mh.df_train[200:200+w.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 'make_dataset' function executes the self-imported 'timeseries_dataset_from_array' function, then splits the data in the respective windows.\n",
    "The \"batch_size\" can be defined here. Also, the \"sequence_stride\" is an important parameter.\n",
    "It can be used to leave out windows and thus reduce the number of generated sequences.\n",
    "This can be useful if lots of data is available.\n",
    "With a sequence_stride of 1 the window is moved to the next starting index, With a sequence stride of 2 the next is skipped.\n",
    "As a result, only half of the sequences are created."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = mh.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=8,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assign properties to create the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorSpec(shape=(None, 16, 9), dtype=tf.float32, name=None),\n TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "w.train.element_spec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile and fit the model with the usual metrics and loss function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "  early_stopping2 = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='max')\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),)\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      #callbacks=[early_stopping2]\n",
    "                      )\n",
    "  return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 2\nInput indices: [0]\nLabel indices: [1]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "single_step_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It follows some testing with simple networks such as:\n",
    "* ordinary Dense Networks\n",
    "* Convolutional Networks\n",
    "* LSTMs\n",
    "* GRUs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.2965 - sparse_categorical_accuracy: 0.2566 - val_loss: 2.1963 - val_sparse_categorical_accuracy: 0.2579\n",
      "Epoch 2/20\n",
      "236/236 [==============================] - 0s 932us/step - loss: 1.9902 - sparse_categorical_accuracy: 0.3155 - val_loss: 2.1776 - val_sparse_categorical_accuracy: 0.2375\n",
      "Epoch 3/20\n",
      "236/236 [==============================] - 0s 750us/step - loss: 1.8852 - sparse_categorical_accuracy: 0.3494 - val_loss: 2.1756 - val_sparse_categorical_accuracy: 0.2486\n",
      "Epoch 4/20\n",
      "236/236 [==============================] - 0s 809us/step - loss: 1.8247 - sparse_categorical_accuracy: 0.3484 - val_loss: 2.1757 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 5/20\n",
      "236/236 [==============================] - 0s 771us/step - loss: 1.7718 - sparse_categorical_accuracy: 0.3786 - val_loss: 2.2241 - val_sparse_categorical_accuracy: 0.2338\n",
      "Epoch 6/20\n",
      "236/236 [==============================] - 0s 758us/step - loss: 1.7186 - sparse_categorical_accuracy: 0.3823 - val_loss: 2.2317 - val_sparse_categorical_accuracy: 0.2393\n",
      "Epoch 7/20\n",
      "236/236 [==============================] - 0s 814us/step - loss: 1.6779 - sparse_categorical_accuracy: 0.4003 - val_loss: 2.2247 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 8/20\n",
      "236/236 [==============================] - 0s 805us/step - loss: 1.6463 - sparse_categorical_accuracy: 0.4014 - val_loss: 2.2299 - val_sparse_categorical_accuracy: 0.2375\n",
      "Epoch 9/20\n",
      "236/236 [==============================] - 0s 742us/step - loss: 1.6086 - sparse_categorical_accuracy: 0.4152 - val_loss: 2.2804 - val_sparse_categorical_accuracy: 0.2263\n",
      "Epoch 10/20\n",
      "236/236 [==============================] - 0s 767us/step - loss: 1.5703 - sparse_categorical_accuracy: 0.4300 - val_loss: 2.2633 - val_sparse_categorical_accuracy: 0.2393\n",
      "Epoch 11/20\n",
      "236/236 [==============================] - 0s 831us/step - loss: 1.5470 - sparse_categorical_accuracy: 0.4443 - val_loss: 2.3154 - val_sparse_categorical_accuracy: 0.2171\n",
      "Epoch 12/20\n",
      "236/236 [==============================] - 0s 695us/step - loss: 1.5145 - sparse_categorical_accuracy: 0.4464 - val_loss: 2.3670 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 13/20\n",
      "236/236 [==============================] - 0s 742us/step - loss: 1.4845 - sparse_categorical_accuracy: 0.4517 - val_loss: 2.3450 - val_sparse_categorical_accuracy: 0.2152\n",
      "Epoch 14/20\n",
      "236/236 [==============================] - 0s 712us/step - loss: 1.4545 - sparse_categorical_accuracy: 0.4772 - val_loss: 2.4191 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 15/20\n",
      "236/236 [==============================] - 0s 691us/step - loss: 1.4218 - sparse_categorical_accuracy: 0.4788 - val_loss: 2.4618 - val_sparse_categorical_accuracy: 0.2263\n",
      "Epoch 16/20\n",
      "236/236 [==============================] - 0s 729us/step - loss: 1.4133 - sparse_categorical_accuracy: 0.4698 - val_loss: 2.5155 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 17/20\n",
      "236/236 [==============================] - 0s 758us/step - loss: 1.3816 - sparse_categorical_accuracy: 0.4799 - val_loss: 2.5616 - val_sparse_categorical_accuracy: 0.2282\n",
      "Epoch 18/20\n",
      "236/236 [==============================] - 0s 725us/step - loss: 1.3598 - sparse_categorical_accuracy: 0.4915 - val_loss: 2.6043 - val_sparse_categorical_accuracy: 0.2134\n",
      "Epoch 19/20\n",
      "236/236 [==============================] - 0s 682us/step - loss: 1.3288 - sparse_categorical_accuracy: 0.5074 - val_loss: 2.6556 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 20/20\n",
      "236/236 [==============================] - 0s 767us/step - loss: 1.3010 - sparse_categorical_accuracy: 0.5154 - val_loss: 2.7034 - val_sparse_categorical_accuracy: 0.2412\n",
      "68/68 [==============================] - 0s 456us/step - loss: 2.7034 - sparse_categorical_accuracy: 0.2412\n"
     ]
    }
   ],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense, single_step_window)\n",
    "\n",
    "val_performance = dense.evaluate(single_step_window.val)\n",
    "performance = dense.evaluate(single_step_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 17\nInput indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\nLabel indices: [16]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_window = WindowGenerator(\n",
    "    input_width=16, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "\n",
    "my_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "234/234 [==============================] - 0s 915us/step - loss: 2.3024 - sparse_categorical_accuracy: 0.2742 - val_loss: 2.3626 - val_sparse_categorical_accuracy: 0.2156\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 0s 778us/step - loss: 1.9594 - sparse_categorical_accuracy: 0.3378 - val_loss: 2.4278 - val_sparse_categorical_accuracy: 0.1908\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 0s 709us/step - loss: 1.7845 - sparse_categorical_accuracy: 0.3891 - val_loss: 2.3818 - val_sparse_categorical_accuracy: 0.2118\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 0s 718us/step - loss: 1.6248 - sparse_categorical_accuracy: 0.4201 - val_loss: 2.5073 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 0s 983us/step - loss: 1.4506 - sparse_categorical_accuracy: 0.4837 - val_loss: 2.6160 - val_sparse_categorical_accuracy: 0.1927\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 0s 782us/step - loss: 1.2735 - sparse_categorical_accuracy: 0.5564 - val_loss: 2.7116 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 0s 739us/step - loss: 1.0909 - sparse_categorical_accuracy: 0.6125 - val_loss: 2.9249 - val_sparse_categorical_accuracy: 0.1908\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 0s 765us/step - loss: 0.9080 - sparse_categorical_accuracy: 0.6718 - val_loss: 3.2664 - val_sparse_categorical_accuracy: 0.1889\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 0s 726us/step - loss: 0.7488 - sparse_categorical_accuracy: 0.7429 - val_loss: 3.5529 - val_sparse_categorical_accuracy: 0.1832\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 0s 714us/step - loss: 0.6070 - sparse_categorical_accuracy: 0.7873 - val_loss: 3.8191 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 0s 726us/step - loss: 0.5095 - sparse_categorical_accuracy: 0.8300 - val_loss: 4.5703 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 0s 727us/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8712 - val_loss: 4.4611 - val_sparse_categorical_accuracy: 0.1927\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 0s 709us/step - loss: 0.3584 - sparse_categorical_accuracy: 0.8792 - val_loss: 5.3520 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 0s 688us/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8888 - val_loss: 5.2756 - val_sparse_categorical_accuracy: 0.1565\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 0s 761us/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9139 - val_loss: 5.8005 - val_sparse_categorical_accuracy: 0.1813\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 0s 889us/step - loss: 0.2442 - sparse_categorical_accuracy: 0.9193 - val_loss: 5.9555 - val_sparse_categorical_accuracy: 0.2137\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 0s 919us/step - loss: 0.2062 - sparse_categorical_accuracy: 0.9294 - val_loss: 6.3975 - val_sparse_categorical_accuracy: 0.1851\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 0s 859us/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9252 - val_loss: 6.5223 - val_sparse_categorical_accuracy: 0.1832\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 0s 761us/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9503 - val_loss: 6.6140 - val_sparse_categorical_accuracy: 0.2004\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 0s 799us/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9482 - val_loss: 7.3522 - val_sparse_categorical_accuracy: 0.1889\n",
      "66/66 [==============================] - 0s 515us/step - loss: 7.3522 - sparse_categorical_accuracy: 0.1889\n"
     ]
    }
   ],
   "source": [
    "dense2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense2, my_window)\n",
    "\n",
    "val_performance = dense2.evaluate(my_window.val)\n",
    "performance = dense2.evaluate(my_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 33\nInput indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31]\nLabel indices: [32]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_window = WindowGenerator(\n",
    "    input_width=32, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "\n",
    "another_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "232/232 [==============================] - 0s 884us/step - loss: 2.4233 - sparse_categorical_accuracy: 0.2469 - val_loss: 2.3766 - val_sparse_categorical_accuracy: 0.2087\n",
      "Epoch 2/20\n",
      "232/232 [==============================] - 0s 759us/step - loss: 2.0182 - sparse_categorical_accuracy: 0.3191 - val_loss: 2.4397 - val_sparse_categorical_accuracy: 0.1890\n",
      "Epoch 3/20\n",
      "232/232 [==============================] - 0s 754us/step - loss: 1.8660 - sparse_categorical_accuracy: 0.3509 - val_loss: 2.5956 - val_sparse_categorical_accuracy: 0.2028\n",
      "Epoch 4/20\n",
      "232/232 [==============================] - 0s 746us/step - loss: 1.6995 - sparse_categorical_accuracy: 0.4205 - val_loss: 2.5933 - val_sparse_categorical_accuracy: 0.1752\n",
      "Epoch 5/20\n",
      "232/232 [==============================] - 0s 716us/step - loss: 1.5141 - sparse_categorical_accuracy: 0.4836 - val_loss: 2.6886 - val_sparse_categorical_accuracy: 0.1673\n",
      "Epoch 6/20\n",
      "232/232 [==============================] - 0s 759us/step - loss: 1.3511 - sparse_categorical_accuracy: 0.5175 - val_loss: 2.9845 - val_sparse_categorical_accuracy: 0.1614\n",
      "Epoch 7/20\n",
      "232/232 [==============================] - 0s 703us/step - loss: 1.1421 - sparse_categorical_accuracy: 0.5919 - val_loss: 3.1182 - val_sparse_categorical_accuracy: 0.1772\n",
      "Epoch 8/20\n",
      "232/232 [==============================] - 0s 728us/step - loss: 0.9886 - sparse_categorical_accuracy: 0.6512 - val_loss: 3.6383 - val_sparse_categorical_accuracy: 0.1693\n",
      "Epoch 9/20\n",
      "232/232 [==============================] - 0s 711us/step - loss: 0.7993 - sparse_categorical_accuracy: 0.7154 - val_loss: 3.9887 - val_sparse_categorical_accuracy: 0.1949\n",
      "Epoch 10/20\n",
      "232/232 [==============================] - 0s 733us/step - loss: 0.6470 - sparse_categorical_accuracy: 0.7801 - val_loss: 4.2018 - val_sparse_categorical_accuracy: 0.1634\n",
      "Epoch 11/20\n",
      "232/232 [==============================] - 0s 711us/step - loss: 0.5656 - sparse_categorical_accuracy: 0.8032 - val_loss: 4.3029 - val_sparse_categorical_accuracy: 0.1988\n",
      "Epoch 12/20\n",
      "232/232 [==============================] - 0s 707us/step - loss: 0.5081 - sparse_categorical_accuracy: 0.8270 - val_loss: 4.6793 - val_sparse_categorical_accuracy: 0.1555\n",
      "Epoch 13/20\n",
      "232/232 [==============================] - 0s 802us/step - loss: 0.4227 - sparse_categorical_accuracy: 0.8507 - val_loss: 5.0053 - val_sparse_categorical_accuracy: 0.1398\n",
      "Epoch 14/20\n",
      "232/232 [==============================] - 0s 853us/step - loss: 0.3595 - sparse_categorical_accuracy: 0.8782 - val_loss: 5.9879 - val_sparse_categorical_accuracy: 0.1437\n",
      "Epoch 15/20\n",
      "232/232 [==============================] - 0s 802us/step - loss: 0.3153 - sparse_categorical_accuracy: 0.8965 - val_loss: 5.3934 - val_sparse_categorical_accuracy: 0.1752\n",
      "Epoch 16/20\n",
      "232/232 [==============================] - 0s 703us/step - loss: 0.3625 - sparse_categorical_accuracy: 0.8755 - val_loss: 5.7667 - val_sparse_categorical_accuracy: 0.1358\n",
      "Epoch 17/20\n",
      "232/232 [==============================] - 0s 703us/step - loss: 0.2970 - sparse_categorical_accuracy: 0.9008 - val_loss: 5.8323 - val_sparse_categorical_accuracy: 0.1417\n",
      "Epoch 18/20\n",
      "232/232 [==============================] - 0s 793us/step - loss: 0.2889 - sparse_categorical_accuracy: 0.9008 - val_loss: 6.5580 - val_sparse_categorical_accuracy: 0.1634\n",
      "Epoch 19/20\n",
      "232/232 [==============================] - 0s 797us/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9143 - val_loss: 6.9155 - val_sparse_categorical_accuracy: 0.1535\n",
      "Epoch 20/20\n",
      "232/232 [==============================] - 0s 789us/step - loss: 0.2375 - sparse_categorical_accuracy: 0.9186 - val_loss: 7.0630 - val_sparse_categorical_accuracy: 0.1457\n",
      "64/64 [==============================] - 0s 406us/step - loss: 7.0630 - sparse_categorical_accuracy: 0.1457\n"
     ]
    }
   ],
   "source": [
    "dense3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense3, another_window)\n",
    "\n",
    "val_performance = dense3.evaluate(another_window.val)\n",
    "performance = dense3.evaluate(another_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "CONV_WIDTH = 10\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=['cat_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.2307 - sparse_categorical_accuracy: 0.2616 - val_loss: 2.2304 - val_sparse_categorical_accuracy: 0.2358\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 0s 770us/step - loss: 1.9956 - sparse_categorical_accuracy: 0.3335 - val_loss: 2.1990 - val_sparse_categorical_accuracy: 0.2340\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 0s 783us/step - loss: 1.8728 - sparse_categorical_accuracy: 0.3596 - val_loss: 2.2241 - val_sparse_categorical_accuracy: 0.2226\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 0s 770us/step - loss: 1.7822 - sparse_categorical_accuracy: 0.3889 - val_loss: 2.2195 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 0s 826us/step - loss: 1.7092 - sparse_categorical_accuracy: 0.4012 - val_loss: 2.2309 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 0s 757us/step - loss: 1.6354 - sparse_categorical_accuracy: 0.4321 - val_loss: 2.3054 - val_sparse_categorical_accuracy: 0.2245\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 0s 915us/step - loss: 1.5457 - sparse_categorical_accuracy: 0.4587 - val_loss: 2.2942 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 0s 804us/step - loss: 1.4558 - sparse_categorical_accuracy: 0.4912 - val_loss: 2.4181 - val_sparse_categorical_accuracy: 0.2151\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 0s 813us/step - loss: 1.3799 - sparse_categorical_accuracy: 0.4955 - val_loss: 2.5687 - val_sparse_categorical_accuracy: 0.2057\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 0s 847us/step - loss: 1.2901 - sparse_categorical_accuracy: 0.5354 - val_loss: 2.6324 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 0s 762us/step - loss: 1.1908 - sparse_categorical_accuracy: 0.5786 - val_loss: 2.8141 - val_sparse_categorical_accuracy: 0.2094\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 0s 821us/step - loss: 1.0864 - sparse_categorical_accuracy: 0.6026 - val_loss: 3.1623 - val_sparse_categorical_accuracy: 0.2151\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 0s 766us/step - loss: 0.9772 - sparse_categorical_accuracy: 0.6532 - val_loss: 3.3069 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 0s 847us/step - loss: 0.8737 - sparse_categorical_accuracy: 0.6739 - val_loss: 3.7489 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7928 - sparse_categorical_accuracy: 0.7075 - val_loss: 3.8905 - val_sparse_categorical_accuracy: 0.2170\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 0s 877us/step - loss: 0.6785 - sparse_categorical_accuracy: 0.7619 - val_loss: 4.4768 - val_sparse_categorical_accuracy: 0.2340\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 0s 838us/step - loss: 0.6192 - sparse_categorical_accuracy: 0.7794 - val_loss: 4.3753 - val_sparse_categorical_accuracy: 0.2396\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 0s 826us/step - loss: 0.5341 - sparse_categorical_accuracy: 0.8071 - val_loss: 5.0857 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 0s 847us/step - loss: 0.4768 - sparse_categorical_accuracy: 0.8258 - val_loss: 5.3347 - val_sparse_categorical_accuracy: 0.2264\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 0s 826us/step - loss: 0.4411 - sparse_categorical_accuracy: 0.8460 - val_loss: 5.6483 - val_sparse_categorical_accuracy: 0.2321\n",
      "67/67 [==============================] - 0s 463us/step - loss: 5.6483 - sparse_categorical_accuracy: 0.2321\n"
     ]
    }
   ],
   "source": [
    "conv_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "\n",
    "history = compile_and_fit(conv_model, conv_window)\n",
    "\n",
    "val_performance = conv_model.evaluate(conv_window.val)\n",
    "performance = conv_model.evaluate(conv_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 9\nInput indices: [0 1 2 3 4 5 6 7]\nLabel indices: [8]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_3 = WindowGenerator(\n",
    "    input_width=8, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "\n",
    "window_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorSpec(shape=(None, 8, 9), dtype=tf.float32, name=None),\n TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "window_3.train.element_spec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.4130 - sparse_categorical_accuracy: 0.2437 - val_loss: 2.2554 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1828 - sparse_categorical_accuracy: 0.2885 - val_loss: 2.2440 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1019 - sparse_categorical_accuracy: 0.3007 - val_loss: 2.2223 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.0531 - sparse_categorical_accuracy: 0.3113 - val_loss: 2.1922 - val_sparse_categorical_accuracy: 0.2481\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.0140 - sparse_categorical_accuracy: 0.3124 - val_loss: 2.1794 - val_sparse_categorical_accuracy: 0.2256\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.9880 - sparse_categorical_accuracy: 0.3252 - val_loss: 2.1723 - val_sparse_categorical_accuracy: 0.2350\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.9314 - sparse_categorical_accuracy: 0.3438 - val_loss: 2.1544 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.9123 - sparse_categorical_accuracy: 0.3363 - val_loss: 2.1386 - val_sparse_categorical_accuracy: 0.2350\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8761 - sparse_categorical_accuracy: 0.3566 - val_loss: 2.1507 - val_sparse_categorical_accuracy: 0.2425\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8401 - sparse_categorical_accuracy: 0.3592 - val_loss: 2.1405 - val_sparse_categorical_accuracy: 0.2425\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.7776 - sparse_categorical_accuracy: 0.3741 - val_loss: 2.1480 - val_sparse_categorical_accuracy: 0.2387\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.7372 - sparse_categorical_accuracy: 0.3896 - val_loss: 2.1715 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6985 - sparse_categorical_accuracy: 0.4039 - val_loss: 2.3201 - val_sparse_categorical_accuracy: 0.2613\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6547 - sparse_categorical_accuracy: 0.4093 - val_loss: 2.2176 - val_sparse_categorical_accuracy: 0.2575\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6141 - sparse_categorical_accuracy: 0.4188 - val_loss: 2.2623 - val_sparse_categorical_accuracy: 0.2575\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.5876 - sparse_categorical_accuracy: 0.4305 - val_loss: 2.3415 - val_sparse_categorical_accuracy: 0.2632\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.5432 - sparse_categorical_accuracy: 0.4561 - val_loss: 2.4642 - val_sparse_categorical_accuracy: 0.2763\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4864 - sparse_categorical_accuracy: 0.4774 - val_loss: 2.5275 - val_sparse_categorical_accuracy: 0.2387\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.4665 - sparse_categorical_accuracy: 0.4715 - val_loss: 2.4595 - val_sparse_categorical_accuracy: 0.2744\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.4210 - sparse_categorical_accuracy: 0.4870 - val_loss: 2.6274 - val_sparse_categorical_accuracy: 0.2481\n",
      "67/67 [==============================] - 0s 955us/step - loss: 2.6274 - sparse_categorical_accuracy: 0.2481\n"
     ]
    }
   ],
   "source": [
    "lstm = tf.keras.Sequential()\n",
    "lstm.add(tf.keras.layers.LSTM(128,return_sequences=True,input_shape=(8, 9), activation='relu'))\n",
    "lstm.add(tf.keras.layers.LSTM(64,input_shape=(8, 9), activation='relu'))\n",
    "lstm.add(tf.keras.layers.Dropout(0.5))\n",
    "lstm.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "history = compile_and_fit(lstm, window_3)\n",
    "\n",
    "val_performance = lstm.evaluate(window_3.val)\n",
    "performance = lstm.evaluate(window_3.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.4007 - sparse_categorical_accuracy: 0.2576 - val_loss: 2.2953 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.1227 - sparse_categorical_accuracy: 0.2906 - val_loss: 2.1800 - val_sparse_categorical_accuracy: 0.2425\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 2.0210 - sparse_categorical_accuracy: 0.3321 - val_loss: 2.1677 - val_sparse_categorical_accuracy: 0.2556\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.9482 - sparse_categorical_accuracy: 0.3363 - val_loss: 2.1346 - val_sparse_categorical_accuracy: 0.2594\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8953 - sparse_categorical_accuracy: 0.3513 - val_loss: 2.1367 - val_sparse_categorical_accuracy: 0.2669\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8426 - sparse_categorical_accuracy: 0.3699 - val_loss: 2.1546 - val_sparse_categorical_accuracy: 0.2669\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.7736 - sparse_categorical_accuracy: 0.3938 - val_loss: 2.1479 - val_sparse_categorical_accuracy: 0.2726\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.7136 - sparse_categorical_accuracy: 0.4156 - val_loss: 2.1234 - val_sparse_categorical_accuracy: 0.2782\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6843 - sparse_categorical_accuracy: 0.4162 - val_loss: 2.1151 - val_sparse_categorical_accuracy: 0.2744\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.6236 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.1349 - val_sparse_categorical_accuracy: 0.2688\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.5704 - sparse_categorical_accuracy: 0.4524 - val_loss: 2.2043 - val_sparse_categorical_accuracy: 0.2688\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.5199 - sparse_categorical_accuracy: 0.4768 - val_loss: 2.2467 - val_sparse_categorical_accuracy: 0.2707\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.4505 - sparse_categorical_accuracy: 0.4880 - val_loss: 2.3202 - val_sparse_categorical_accuracy: 0.2650\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.3958 - sparse_categorical_accuracy: 0.5008 - val_loss: 2.2937 - val_sparse_categorical_accuracy: 0.2650\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.3842 - sparse_categorical_accuracy: 0.5290 - val_loss: 2.3714 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.3197 - sparse_categorical_accuracy: 0.5439 - val_loss: 2.4468 - val_sparse_categorical_accuracy: 0.2782\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.2715 - sparse_categorical_accuracy: 0.5444 - val_loss: 2.5982 - val_sparse_categorical_accuracy: 0.2556\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.1986 - sparse_categorical_accuracy: 0.5764 - val_loss: 2.8690 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.1578 - sparse_categorical_accuracy: 0.5716 - val_loss: 2.9133 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.1040 - sparse_categorical_accuracy: 0.6046 - val_loss: 2.9274 - val_sparse_categorical_accuracy: 0.2650\n",
      "67/67 [==============================] - 0s 925us/step - loss: 2.9274 - sparse_categorical_accuracy: 0.2650\n"
     ]
    }
   ],
   "source": [
    "gru1 = tf.keras.Sequential()\n",
    "gru1.add(tf.keras.layers.GRU(128,return_sequences=True,input_shape=(8, 9), activation='relu'))\n",
    "gru1.add(tf.keras.layers.GRU(64,input_shape=(8, 9), activation='relu'))\n",
    "gru1.add(tf.keras.layers.Dropout(0.5))\n",
    "gru1.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "history = compile_and_fit(gru1, window_3)\n",
    "\n",
    "val_performance = gru1.evaluate(window_3.val)\n",
    "performance = gru1.evaluate(window_3.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2.4968 - sparse_categorical_accuracy: 0.2333 - val_loss: 2.2547 - val_sparse_categorical_accuracy: 0.2301\n",
      "Epoch 2/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.1330 - sparse_categorical_accuracy: 0.2847 - val_loss: 2.1773 - val_sparse_categorical_accuracy: 0.2430\n",
      "Epoch 3/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.0627 - sparse_categorical_accuracy: 0.2959 - val_loss: 2.1671 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 4/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.0167 - sparse_categorical_accuracy: 0.2948 - val_loss: 2.1752 - val_sparse_categorical_accuracy: 0.2393\n",
      "Epoch 5/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.9738 - sparse_categorical_accuracy: 0.3277 - val_loss: 2.1985 - val_sparse_categorical_accuracy: 0.2486\n",
      "Epoch 6/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.9285 - sparse_categorical_accuracy: 0.3319 - val_loss: 2.1575 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 7/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.9118 - sparse_categorical_accuracy: 0.3324 - val_loss: 2.1497 - val_sparse_categorical_accuracy: 0.2579\n",
      "Epoch 8/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8712 - sparse_categorical_accuracy: 0.3515 - val_loss: 2.1791 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 9/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8578 - sparse_categorical_accuracy: 0.3637 - val_loss: 2.1521 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 10/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8407 - sparse_categorical_accuracy: 0.3584 - val_loss: 2.1610 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 11/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8119 - sparse_categorical_accuracy: 0.3918 - val_loss: 2.1577 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 12/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8170 - sparse_categorical_accuracy: 0.3558 - val_loss: 2.1554 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 13/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7775 - sparse_categorical_accuracy: 0.3892 - val_loss: 2.1389 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 14/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7638 - sparse_categorical_accuracy: 0.3892 - val_loss: 2.1956 - val_sparse_categorical_accuracy: 0.2597\n",
      "Epoch 15/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7473 - sparse_categorical_accuracy: 0.3786 - val_loss: 2.1785 - val_sparse_categorical_accuracy: 0.2709\n",
      "Epoch 16/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7401 - sparse_categorical_accuracy: 0.3918 - val_loss: 2.1998 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 17/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7380 - sparse_categorical_accuracy: 0.3849 - val_loss: 2.1868 - val_sparse_categorical_accuracy: 0.2486\n",
      "Epoch 18/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7148 - sparse_categorical_accuracy: 0.3966 - val_loss: 2.1973 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 19/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7033 - sparse_categorical_accuracy: 0.3849 - val_loss: 2.2162 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 20/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7090 - sparse_categorical_accuracy: 0.3860 - val_loss: 2.1519 - val_sparse_categorical_accuracy: 0.2672\n",
      "68/68 [==============================] - 0s 529us/step - loss: 2.1519 - sparse_categorical_accuracy: 0.2672\n"
     ]
    }
   ],
   "source": [
    "gru2 = tf.keras.Sequential()\n",
    "gru2.add(tf.keras.layers.GRU(128,return_sequences=True,input_shape=(1, 9), activation='relu'))\n",
    "gru2.add(tf.keras.layers.GRU(64,input_shape=(1, 9), activation='relu'))\n",
    "gru2.add(tf.keras.layers.Dropout(0.5))\n",
    "gru2.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "history = compile_and_fit(gru2, single_step_window)\n",
    "\n",
    "val_performance = gru2.evaluate(single_step_window.val)\n",
    "performance = gru2.evaluate(single_step_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}