{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 4 - Dynamic Windowing\n",
    "\n",
    "A tutorial for timeseries prediction with tf was worked through. Here the advantages of Sliding Windows were discussed. Their application possibilities are tested in the following. Sliding windows allow to extract more sequences from the sequenced data than it has been done so far. So far, whole chunks are taken from the data, which are free of overlap. With Sliding Windows, the window is continuously slid over the data set to obtain sequences. With little data available, this could lead to better prediction accuracy.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports\n",
    "\n",
    "\"timeseries_dataset_from_array\" is a function that is not part of the used tf version but is required to transform the data, thus it is manually copied here and modified slightly"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# these functions are copied from a newer version and is needed to run the code below:\n",
    "def timeseries_dataset_from_array(\n",
    "    data,\n",
    "    targets,\n",
    "    sequence_length,\n",
    "    sequence_stride=1,\n",
    "    sampling_rate=1,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    start_index=None,\n",
    "    end_index=None,\n",
    "):\n",
    "    if start_index:\n",
    "        if start_index < 0:\n",
    "            raise ValueError(\n",
    "                \"`start_index` must be 0 or greater. Received: \"\n",
    "                f\"start_index={start_index}\"\n",
    "            )\n",
    "        if start_index >= len(data):\n",
    "            raise ValueError(\n",
    "                \"`start_index` must be lower than the length of the \"\n",
    "                f\"data. Received: start_index={start_index}, for data \"\n",
    "                f\"of length {len(data)}\"\n",
    "            )\n",
    "    if end_index:\n",
    "        if start_index and end_index <= start_index:\n",
    "            raise ValueError(\n",
    "                \"`end_index` must be higher than `start_index`. \"\n",
    "                f\"Received: start_index={start_index}, and \"\n",
    "                f\"end_index={end_index} \"\n",
    "            )\n",
    "        if end_index >= len(data):\n",
    "            raise ValueError(\n",
    "                \"`end_index` must be lower than the length of the \"\n",
    "                f\"data. Received: end_index={end_index}, for data of \"\n",
    "                f\"length {len(data)}\"\n",
    "            )\n",
    "        if end_index <= 0:\n",
    "            raise ValueError(\n",
    "                \"`end_index` must be higher than 0. \"\n",
    "                f\"Received: end_index={end_index}\"\n",
    "            )\n",
    "\n",
    "    # Validate strides\n",
    "    if sampling_rate <= 0:\n",
    "        raise ValueError(\n",
    "            \"`sampling_rate` must be higher than 0. Received: \"\n",
    "            f\"sampling_rate={sampling_rate}\"\n",
    "        )\n",
    "    if sampling_rate >= len(data):\n",
    "        raise ValueError(\n",
    "            \"`sampling_rate` must be lower than the length of the \"\n",
    "            f\"data. Received: sampling_rate={sampling_rate}, for data \"\n",
    "            f\"of length {len(data)}\"\n",
    "        )\n",
    "    if sequence_stride <= 0:\n",
    "        raise ValueError(\n",
    "            \"`sequence_stride` must be higher than 0. Received: \"\n",
    "            f\"sequence_stride={sequence_stride}\"\n",
    "        )\n",
    "    if sequence_stride >= len(data):\n",
    "        raise ValueError(\n",
    "            \"`sequence_stride` must be lower than the length of the \"\n",
    "            f\"data. Received: sequence_stride={sequence_stride}, for \"\n",
    "            f\"data of length {len(data)}\"\n",
    "        )\n",
    "\n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if end_index is None:\n",
    "        end_index = len(data)\n",
    "\n",
    "    # Determine the lowest dtype to store start positions (to lower memory\n",
    "    # usage).\n",
    "    num_seqs = end_index - start_index - (sequence_length * sampling_rate) + 1\n",
    "    if targets is not None:\n",
    "        num_seqs = min(num_seqs, len(targets))\n",
    "    if num_seqs < 2147483647:\n",
    "        index_dtype = \"int32\"\n",
    "    else:\n",
    "        index_dtype = \"int64\"\n",
    "\n",
    "    # Generate start positions\n",
    "    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n",
    "    if shuffle:\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(1e6)\n",
    "        rng = np.random.RandomState(seed)\n",
    "        rng.shuffle(start_positions)\n",
    "\n",
    "    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n",
    "    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n",
    "\n",
    "    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n",
    "\n",
    "    # For each initial window position, generates indices of the window elements\n",
    "    indices = tf.data.Dataset.zip(\n",
    "        (tf.data.Dataset.range(len(start_positions)), positions_ds)\n",
    "    ).map(\n",
    "        lambda i, positions: tf.range(\n",
    "            positions[i],\n",
    "            positions[i] + sequence_length * sampling_rate,\n",
    "            sampling_rate,\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    dataset = sequences_from_indices(data, indices, start_index, end_index)\n",
    "    if targets is not None:\n",
    "        indices = tf.data.Dataset.zip(\n",
    "            (tf.data.Dataset.range(len(start_positions)), positions_ds)\n",
    "        ).map(\n",
    "            lambda i, positions: positions[i],\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "        )\n",
    "        target_ds = sequences_from_indices(\n",
    "            targets, indices, start_index, end_index\n",
    "        )\n",
    "        dataset = tf.data.Dataset.zip((dataset, target_ds))\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    if batch_size is not None:\n",
    "        if shuffle:\n",
    "            # Shuffle locally at each iteration\n",
    "            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    else:\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n",
    "    return dataset\n",
    "\n",
    "def sequences_from_indices(array, indices_ds, start_index, end_index):\n",
    "    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n",
    "    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(\n",
    "        lambda steps, inds: tf.gather(steps, inds),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The usual reading of the csv and setting of the vocabulary size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  27\n"
     ]
    },
    {
     "data": {
      "text/plain": "   user_id  cat_id  clock_sin  clock_cos   day_sin   day_cos  month_sin  \\\n0      470       0  -1.000000   0.000654  0.587785  0.809017   0.866025   \n1      979       1  -0.999998   0.001818  0.587785  0.809017   0.866025   \n2       69       2  -0.999945   0.010472  0.587785  0.809017   0.866025   \n3      395       3  -0.999931   0.011708  0.587785  0.809017   0.866025   \n4       87       4  -0.999914   0.013090  0.587785  0.809017   0.866025   \n5      484       5  -0.999848   0.017452  0.587785  0.809017   0.866025   \n6      642       6  -0.999796   0.020215  0.587785  0.809017   0.866025   \n7      292       7  -0.999790   0.020506  0.587785  0.809017   0.866025   \n8      428       2  -0.999622   0.027485  0.587785  0.809017   0.866025   \n9      877       8  -0.999620   0.027558  0.587785  0.809017   0.866025   \n\n   month_cos  week_day_sin  week_day_cos  \n0       -0.5      0.781831       0.62349  \n1       -0.5      0.781831       0.62349  \n2       -0.5      0.781831       0.62349  \n3       -0.5      0.781831       0.62349  \n4       -0.5      0.781831       0.62349  \n5       -0.5      0.781831       0.62349  \n6       -0.5      0.781831       0.62349  \n7       -0.5      0.781831       0.62349  \n8       -0.5      0.781831       0.62349  \n9       -0.5      0.781831       0.62349  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>cat_id</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>470</td>\n      <td>0</td>\n      <td>-1.000000</td>\n      <td>0.000654</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>979</td>\n      <td>1</td>\n      <td>-0.999998</td>\n      <td>0.001818</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>69</td>\n      <td>2</td>\n      <td>-0.999945</td>\n      <td>0.010472</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>395</td>\n      <td>3</td>\n      <td>-0.999931</td>\n      <td>0.011708</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>87</td>\n      <td>4</td>\n      <td>-0.999914</td>\n      <td>0.013090</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>484</td>\n      <td>5</td>\n      <td>-0.999848</td>\n      <td>0.017452</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>642</td>\n      <td>6</td>\n      <td>-0.999796</td>\n      <td>0.020215</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>292</td>\n      <td>7</td>\n      <td>-0.999790</td>\n      <td>0.020506</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>428</td>\n      <td>2</td>\n      <td>-0.999622</td>\n      <td>0.027485</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>877</td>\n      <td>8</td>\n      <td>-0.999620</td>\n      <td>0.027558</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.62349</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./4square/processed_transformed_old.csv\")\n",
    "\n",
    "categories = df.cat_id\n",
    "vocab_size = categories.nunique()\n",
    "\n",
    "print('vocab size: ', vocab_size)\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only the data of a single user is used. As a result only 2697 rows are available."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        user_id  cat_id  clock_sin  clock_cos   day_sin   day_cos  month_sin  \\\n690         293       7  -0.014326   0.999897  0.587785  0.809017   0.866025   \n760         293      14   0.083750   0.996487  0.743145  0.669131   0.866025   \n763         293       9   0.085997   0.996295  0.743145  0.669131   0.866025   \n766         293       0   0.092371   0.995725  0.743145  0.669131   0.866025   \n1121        293       2   0.957697   0.287778  0.743145  0.669131   0.866025   \n...         ...     ...        ...        ...       ...       ...        ...   \n227266      293       7   0.975614   0.219491  0.207912 -0.978148   0.866025   \n227273      293       5   0.984131   0.177443  0.207912 -0.978148   0.866025   \n227274      293       5   0.984350   0.176226  0.207912 -0.978148   0.866025   \n227276      293       7   0.984605   0.174794  0.207912 -0.978148   0.866025   \n227401      293       0   0.528809   0.848741 -0.207912 -0.978148   0.866025   \n\n        month_cos  week_day_sin  week_day_cos  \n690          -0.5      0.781831      0.623490  \n760          -0.5      0.974928     -0.222521  \n763          -0.5      0.974928     -0.222521  \n766          -0.5      0.974928     -0.222521  \n1121         -0.5      0.974928     -0.222521  \n...           ...           ...           ...  \n227266        0.5      0.433884     -0.900969  \n227273        0.5      0.433884     -0.900969  \n227274        0.5      0.433884     -0.900969  \n227276        0.5      0.433884     -0.900969  \n227401        0.5     -0.974928     -0.222521  \n\n[2697 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>cat_id</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>690</th>\n      <td>293</td>\n      <td>7</td>\n      <td>-0.014326</td>\n      <td>0.999897</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>293</td>\n      <td>14</td>\n      <td>0.083750</td>\n      <td>0.996487</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>293</td>\n      <td>9</td>\n      <td>0.085997</td>\n      <td>0.996295</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>293</td>\n      <td>0</td>\n      <td>0.092371</td>\n      <td>0.995725</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>293</td>\n      <td>2</td>\n      <td>0.957697</td>\n      <td>0.287778</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>227266</th>\n      <td>293</td>\n      <td>7</td>\n      <td>0.975614</td>\n      <td>0.219491</td>\n      <td>0.207912</td>\n      <td>-0.978148</td>\n      <td>0.866025</td>\n      <td>0.5</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>227273</th>\n      <td>293</td>\n      <td>5</td>\n      <td>0.984131</td>\n      <td>0.177443</td>\n      <td>0.207912</td>\n      <td>-0.978148</td>\n      <td>0.866025</td>\n      <td>0.5</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>227274</th>\n      <td>293</td>\n      <td>5</td>\n      <td>0.984350</td>\n      <td>0.176226</td>\n      <td>0.207912</td>\n      <td>-0.978148</td>\n      <td>0.866025</td>\n      <td>0.5</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>227276</th>\n      <td>293</td>\n      <td>7</td>\n      <td>0.984605</td>\n      <td>0.174794</td>\n      <td>0.207912</td>\n      <td>-0.978148</td>\n      <td>0.866025</td>\n      <td>0.5</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>227401</th>\n      <td>293</td>\n      <td>0</td>\n      <td>0.528809</td>\n      <td>0.848741</td>\n      <td>-0.207912</td>\n      <td>-0.978148</td>\n      <td>0.866025</td>\n      <td>0.5</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n  </tbody>\n</table>\n<p>2697 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df.user_id == 293].copy()\n",
    "df.head(10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      cat_id  clock_sin  clock_cos   day_sin   day_cos  month_sin  month_cos  \\\n690        7  -0.014326   0.999897  0.587785  0.809017   0.866025       -0.5   \n760       14   0.083750   0.996487  0.743145  0.669131   0.866025       -0.5   \n763        9   0.085997   0.996295  0.743145  0.669131   0.866025       -0.5   \n766        0   0.092371   0.995725  0.743145  0.669131   0.866025       -0.5   \n1121       2   0.957697   0.287778  0.743145  0.669131   0.866025       -0.5   \n1122      14   0.958323   0.285688  0.743145  0.669131   0.866025       -0.5   \n1133       7   0.974826   0.222967  0.743145  0.669131   0.866025       -0.5   \n1811       2  -0.815927  -0.578154  0.743145  0.669131   0.866025       -0.5   \n1862       2  -0.900224  -0.435428  0.743145  0.669131   0.866025       -0.5   \n1866       7  -0.903647  -0.428278  0.743145  0.669131   0.866025       -0.5   \n\n      week_day_sin  week_day_cos  \n690       0.781831      0.623490  \n760       0.974928     -0.222521  \n763       0.974928     -0.222521  \n766       0.974928     -0.222521  \n1121      0.974928     -0.222521  \n1122      0.974928     -0.222521  \n1133      0.974928     -0.222521  \n1811      0.974928     -0.222521  \n1862      0.974928     -0.222521  \n1866      0.974928     -0.222521  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_id</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>690</th>\n      <td>7</td>\n      <td>-0.014326</td>\n      <td>0.999897</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>14</td>\n      <td>0.083750</td>\n      <td>0.996487</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>9</td>\n      <td>0.085997</td>\n      <td>0.996295</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>0</td>\n      <td>0.092371</td>\n      <td>0.995725</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>2</td>\n      <td>0.957697</td>\n      <td>0.287778</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1122</th>\n      <td>14</td>\n      <td>0.958323</td>\n      <td>0.285688</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1133</th>\n      <td>7</td>\n      <td>0.974826</td>\n      <td>0.222967</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1811</th>\n      <td>2</td>\n      <td>-0.815927</td>\n      <td>-0.578154</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1862</th>\n      <td>2</td>\n      <td>-0.900224</td>\n      <td>-0.435428</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1866</th>\n      <td>7</td>\n      <td>-0.903647</td>\n      <td>-0.428278</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['user_id'], axis=1, inplace=True)\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train/Val/Test splitting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       cat_id  clock_sin  clock_cos   day_sin   day_cos  month_sin  month_cos  \\\n690         7  -0.014326   0.999897  0.587785  0.809017   0.866025       -0.5   \n760        14   0.083750   0.996487  0.743145  0.669131   0.866025       -0.5   \n763         9   0.085997   0.996295  0.743145  0.669131   0.866025       -0.5   \n766         0   0.092371   0.995725  0.743145  0.669131   0.866025       -0.5   \n1121        2   0.957697   0.287778  0.743145  0.669131   0.866025       -0.5   \n...       ...        ...        ...       ...       ...        ...        ...   \n13791       2  -0.902992  -0.429658  0.406737 -0.913545   0.866025       -0.5   \n13793       7  -0.904300  -0.426898  0.406737 -0.913545   0.866025       -0.5   \n13794       7  -0.904858  -0.425713  0.406737 -0.913545   0.866025       -0.5   \n13798       7  -0.906830  -0.421497  0.406737 -0.913545   0.866025       -0.5   \n14702       7  -0.037806   0.999285  0.406737 -0.913545   0.866025       -0.5   \n\n       week_day_sin  week_day_cos  \n690        0.781831      0.623490  \n760        0.974928     -0.222521  \n763        0.974928     -0.222521  \n766        0.974928     -0.222521  \n1121       0.974928     -0.222521  \n...             ...           ...  \n13791     -0.433884     -0.900969  \n13793     -0.433884     -0.900969  \n13794     -0.433884     -0.900969  \n13798     -0.433884     -0.900969  \n14702     -0.433884     -0.900969  \n\n[100 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_id</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>690</th>\n      <td>7</td>\n      <td>-0.014326</td>\n      <td>0.999897</td>\n      <td>0.587785</td>\n      <td>0.809017</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>14</td>\n      <td>0.083750</td>\n      <td>0.996487</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>9</td>\n      <td>0.085997</td>\n      <td>0.996295</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>0</td>\n      <td>0.092371</td>\n      <td>0.995725</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>2</td>\n      <td>0.957697</td>\n      <td>0.287778</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13791</th>\n      <td>2</td>\n      <td>-0.902992</td>\n      <td>-0.429658</td>\n      <td>0.406737</td>\n      <td>-0.913545</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13793</th>\n      <td>7</td>\n      <td>-0.904300</td>\n      <td>-0.426898</td>\n      <td>0.406737</td>\n      <td>-0.913545</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13794</th>\n      <td>7</td>\n      <td>-0.904858</td>\n      <td>-0.425713</td>\n      <td>0.406737</td>\n      <td>-0.913545</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13798</th>\n      <td>7</td>\n      <td>-0.906830</td>\n      <td>-0.421497</td>\n      <td>0.406737</td>\n      <td>-0.913545</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>14702</th>\n      <td>7</td>\n      <td>-0.037806</td>\n      <td>0.999285</td>\n      <td>0.406737</td>\n      <td>-0.913545</td>\n      <td>0.866025</td>\n      <td>-0.5</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "train_df.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        cat_id  clock_sin  clock_cos   day_sin   day_cos  month_sin  \\\n215900       2   0.950040  -0.312128 -0.866025  0.500000   0.500000   \n215901       5   0.949243  -0.314545 -0.866025  0.500000   0.500000   \n215906       7   0.917755  -0.397148 -0.866025  0.500000   0.500000   \n216130       2  -0.999958  -0.009163 -0.866025  0.500000   0.500000   \n216131       5  -0.999985  -0.005454 -0.866025  0.500000   0.500000   \n...        ...        ...        ...       ...       ...        ...   \n220005       2   0.976075   0.217433  0.207912  0.978148   0.866025   \n220009       7   0.980472   0.196659  0.207912  0.978148   0.866025   \n220405       2  -0.759177   0.650885  0.207912  0.978148   0.866025   \n220408       7  -0.755758   0.654851  0.207912  0.978148   0.866025   \n220409       7  -0.754423   0.656388  0.207912  0.978148   0.866025   \n\n        month_cos  week_day_sin  week_day_cos  \n215900   0.866025     -0.433884     -0.900969  \n215901   0.866025     -0.433884     -0.900969  \n215906   0.866025     -0.433884     -0.900969  \n216130   0.866025     -0.433884     -0.900969  \n216131   0.866025     -0.433884     -0.900969  \n...           ...           ...           ...  \n220005   0.500000     -0.433884     -0.900969  \n220009   0.500000     -0.433884     -0.900969  \n220405   0.500000     -0.433884     -0.900969  \n220408   0.500000     -0.433884     -0.900969  \n220409   0.500000     -0.433884     -0.900969  \n\n[100 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat_id</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>215900</th>\n      <td>2</td>\n      <td>0.950040</td>\n      <td>-0.312128</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>215901</th>\n      <td>5</td>\n      <td>0.949243</td>\n      <td>-0.314545</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>215906</th>\n      <td>7</td>\n      <td>0.917755</td>\n      <td>-0.397148</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>216130</th>\n      <td>2</td>\n      <td>-0.999958</td>\n      <td>-0.009163</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>216131</th>\n      <td>5</td>\n      <td>-0.999985</td>\n      <td>-0.005454</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>220005</th>\n      <td>2</td>\n      <td>0.976075</td>\n      <td>0.217433</td>\n      <td>0.207912</td>\n      <td>0.978148</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>220009</th>\n      <td>7</td>\n      <td>0.980472</td>\n      <td>0.196659</td>\n      <td>0.207912</td>\n      <td>0.978148</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>220405</th>\n      <td>2</td>\n      <td>-0.759177</td>\n      <td>0.650885</td>\n      <td>0.207912</td>\n      <td>0.978148</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>220408</th>\n      <td>7</td>\n      <td>-0.755758</td>\n      <td>0.654851</td>\n      <td>0.207912</td>\n      <td>0.978148</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>220409</th>\n      <td>7</td>\n      <td>-0.754423</td>\n      <td>0.656388</td>\n      <td>0.207912</td>\n      <td>0.978148</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The WindowGenerator class gets the train/val/test data as well as several other parameters:\n",
    "* input_width - defines the length of the input as part of the window\n",
    "* label_width - defines the length of the label (prediction target) as part of the window, can be used to predict multiple time steps in the future\n",
    "* shift - offsets the label by the respective number of (time) steps\n",
    "* label_columns - the columns used for the prediction\n",
    "\n",
    "Examples found below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exemplary window, output shows the indices."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 17\nInput indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\nLabel indices: [16]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = WindowGenerator(input_width=16, label_width=1, shift=1,\n",
    "                     label_columns=['cat_id'])\n",
    "w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 'split_window' function does the slicing of the dataset according to the window indices."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An example follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (batch, time, features)\n",
      "Window shape: (3, 17, 9)\n",
      "Inputs shape: (3, 16, 9)\n",
      "Labels shape: (3, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Stack three slices, the length of the total window.\n",
    "example_window = tf.stack([np.array(train_df[:w.total_window_size]),\n",
    "                           np.array(train_df[100:100+w.total_window_size]),\n",
    "                           np.array(train_df[200:200+w.total_window_size])])\n",
    "\n",
    "example_inputs, example_labels = w.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 'make_dataset' function executes the self-imported 'timeseries_dataset_from_array' function, then splits the data in the respective windows.\n",
    "The \"batch_size\" can be defined here. Also, the \"sequence_stride\" is an important parameter.\n",
    "It can be used to leave out windows and thus reduce the number of generated sequences.\n",
    "This can be useful if lots of data is available.\n",
    "With a sequence_stride of 1 the window is moved to the next starting index, With a sequence stride of 2 the next is skipped.\n",
    "As a result, only half of the sequences are created."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=8,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assign properties to create the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorSpec(shape=(None, 16, 9), dtype=tf.float32, name=None),\n TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "w.train.element_spec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(df.columns)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile and fit the model with the usual metrics and loss function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "  early_stopping2 = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='max')\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.002),)\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      #callbacks=[early_stopping2]\n",
    "                      )\n",
    "  return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 2\nInput indices: [0]\nLabel indices: [1]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "single_step_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It follows some testing with simple networks such as:\n",
    "* ordinary Dense Networks\n",
    "* Convolutional Networks\n",
    "* LSTMs\n",
    "* GRUs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.2965 - sparse_categorical_accuracy: 0.2566 - val_loss: 2.1963 - val_sparse_categorical_accuracy: 0.2579\n",
      "Epoch 2/20\n",
      "236/236 [==============================] - 0s 932us/step - loss: 1.9902 - sparse_categorical_accuracy: 0.3155 - val_loss: 2.1776 - val_sparse_categorical_accuracy: 0.2375\n",
      "Epoch 3/20\n",
      "236/236 [==============================] - 0s 750us/step - loss: 1.8852 - sparse_categorical_accuracy: 0.3494 - val_loss: 2.1756 - val_sparse_categorical_accuracy: 0.2486\n",
      "Epoch 4/20\n",
      "236/236 [==============================] - 0s 809us/step - loss: 1.8247 - sparse_categorical_accuracy: 0.3484 - val_loss: 2.1757 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 5/20\n",
      "236/236 [==============================] - 0s 771us/step - loss: 1.7718 - sparse_categorical_accuracy: 0.3786 - val_loss: 2.2241 - val_sparse_categorical_accuracy: 0.2338\n",
      "Epoch 6/20\n",
      "236/236 [==============================] - 0s 758us/step - loss: 1.7186 - sparse_categorical_accuracy: 0.3823 - val_loss: 2.2317 - val_sparse_categorical_accuracy: 0.2393\n",
      "Epoch 7/20\n",
      "236/236 [==============================] - 0s 814us/step - loss: 1.6779 - sparse_categorical_accuracy: 0.4003 - val_loss: 2.2247 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 8/20\n",
      "236/236 [==============================] - 0s 805us/step - loss: 1.6463 - sparse_categorical_accuracy: 0.4014 - val_loss: 2.2299 - val_sparse_categorical_accuracy: 0.2375\n",
      "Epoch 9/20\n",
      "236/236 [==============================] - 0s 742us/step - loss: 1.6086 - sparse_categorical_accuracy: 0.4152 - val_loss: 2.2804 - val_sparse_categorical_accuracy: 0.2263\n",
      "Epoch 10/20\n",
      "236/236 [==============================] - 0s 767us/step - loss: 1.5703 - sparse_categorical_accuracy: 0.4300 - val_loss: 2.2633 - val_sparse_categorical_accuracy: 0.2393\n",
      "Epoch 11/20\n",
      "236/236 [==============================] - 0s 831us/step - loss: 1.5470 - sparse_categorical_accuracy: 0.4443 - val_loss: 2.3154 - val_sparse_categorical_accuracy: 0.2171\n",
      "Epoch 12/20\n",
      "236/236 [==============================] - 0s 695us/step - loss: 1.5145 - sparse_categorical_accuracy: 0.4464 - val_loss: 2.3670 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 13/20\n",
      "236/236 [==============================] - 0s 742us/step - loss: 1.4845 - sparse_categorical_accuracy: 0.4517 - val_loss: 2.3450 - val_sparse_categorical_accuracy: 0.2152\n",
      "Epoch 14/20\n",
      "236/236 [==============================] - 0s 712us/step - loss: 1.4545 - sparse_categorical_accuracy: 0.4772 - val_loss: 2.4191 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 15/20\n",
      "236/236 [==============================] - 0s 691us/step - loss: 1.4218 - sparse_categorical_accuracy: 0.4788 - val_loss: 2.4618 - val_sparse_categorical_accuracy: 0.2263\n",
      "Epoch 16/20\n",
      "236/236 [==============================] - 0s 729us/step - loss: 1.4133 - sparse_categorical_accuracy: 0.4698 - val_loss: 2.5155 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 17/20\n",
      "236/236 [==============================] - 0s 758us/step - loss: 1.3816 - sparse_categorical_accuracy: 0.4799 - val_loss: 2.5616 - val_sparse_categorical_accuracy: 0.2282\n",
      "Epoch 18/20\n",
      "236/236 [==============================] - 0s 725us/step - loss: 1.3598 - sparse_categorical_accuracy: 0.4915 - val_loss: 2.6043 - val_sparse_categorical_accuracy: 0.2134\n",
      "Epoch 19/20\n",
      "236/236 [==============================] - 0s 682us/step - loss: 1.3288 - sparse_categorical_accuracy: 0.5074 - val_loss: 2.6556 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 20/20\n",
      "236/236 [==============================] - 0s 767us/step - loss: 1.3010 - sparse_categorical_accuracy: 0.5154 - val_loss: 2.7034 - val_sparse_categorical_accuracy: 0.2412\n",
      "68/68 [==============================] - 0s 456us/step - loss: 2.7034 - sparse_categorical_accuracy: 0.2412\n"
     ]
    }
   ],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense, single_step_window)\n",
    "\n",
    "val_performance = dense.evaluate(single_step_window.val)\n",
    "performance = dense.evaluate(single_step_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 17\nInput indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\nLabel indices: [16]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_window = WindowGenerator(\n",
    "    input_width=16, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "\n",
    "my_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "234/234 [==============================] - 0s 915us/step - loss: 2.3024 - sparse_categorical_accuracy: 0.2742 - val_loss: 2.3626 - val_sparse_categorical_accuracy: 0.2156\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 0s 778us/step - loss: 1.9594 - sparse_categorical_accuracy: 0.3378 - val_loss: 2.4278 - val_sparse_categorical_accuracy: 0.1908\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 0s 709us/step - loss: 1.7845 - sparse_categorical_accuracy: 0.3891 - val_loss: 2.3818 - val_sparse_categorical_accuracy: 0.2118\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 0s 718us/step - loss: 1.6248 - sparse_categorical_accuracy: 0.4201 - val_loss: 2.5073 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 0s 983us/step - loss: 1.4506 - sparse_categorical_accuracy: 0.4837 - val_loss: 2.6160 - val_sparse_categorical_accuracy: 0.1927\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 0s 782us/step - loss: 1.2735 - sparse_categorical_accuracy: 0.5564 - val_loss: 2.7116 - val_sparse_categorical_accuracy: 0.1870\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 0s 739us/step - loss: 1.0909 - sparse_categorical_accuracy: 0.6125 - val_loss: 2.9249 - val_sparse_categorical_accuracy: 0.1908\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 0s 765us/step - loss: 0.9080 - sparse_categorical_accuracy: 0.6718 - val_loss: 3.2664 - val_sparse_categorical_accuracy: 0.1889\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 0s 726us/step - loss: 0.7488 - sparse_categorical_accuracy: 0.7429 - val_loss: 3.5529 - val_sparse_categorical_accuracy: 0.1832\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 0s 714us/step - loss: 0.6070 - sparse_categorical_accuracy: 0.7873 - val_loss: 3.8191 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 0s 726us/step - loss: 0.5095 - sparse_categorical_accuracy: 0.8300 - val_loss: 4.5703 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 0s 727us/step - loss: 0.4106 - sparse_categorical_accuracy: 0.8712 - val_loss: 4.4611 - val_sparse_categorical_accuracy: 0.1927\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 0s 709us/step - loss: 0.3584 - sparse_categorical_accuracy: 0.8792 - val_loss: 5.3520 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 0s 688us/step - loss: 0.3228 - sparse_categorical_accuracy: 0.8888 - val_loss: 5.2756 - val_sparse_categorical_accuracy: 0.1565\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 0s 761us/step - loss: 0.2617 - sparse_categorical_accuracy: 0.9139 - val_loss: 5.8005 - val_sparse_categorical_accuracy: 0.1813\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 0s 889us/step - loss: 0.2442 - sparse_categorical_accuracy: 0.9193 - val_loss: 5.9555 - val_sparse_categorical_accuracy: 0.2137\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 0s 919us/step - loss: 0.2062 - sparse_categorical_accuracy: 0.9294 - val_loss: 6.3975 - val_sparse_categorical_accuracy: 0.1851\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 0s 859us/step - loss: 0.2232 - sparse_categorical_accuracy: 0.9252 - val_loss: 6.5223 - val_sparse_categorical_accuracy: 0.1832\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 0s 761us/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9503 - val_loss: 6.6140 - val_sparse_categorical_accuracy: 0.2004\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 0s 799us/step - loss: 0.1552 - sparse_categorical_accuracy: 0.9482 - val_loss: 7.3522 - val_sparse_categorical_accuracy: 0.1889\n",
      "66/66 [==============================] - 0s 515us/step - loss: 7.3522 - sparse_categorical_accuracy: 0.1889\n"
     ]
    }
   ],
   "source": [
    "dense2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense2, my_window)\n",
    "\n",
    "val_performance = dense2.evaluate(my_window.val)\n",
    "performance = dense2.evaluate(my_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 33\nInput indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31]\nLabel indices: [32]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_window = WindowGenerator(\n",
    "    input_width=32, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "\n",
    "another_window"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "232/232 [==============================] - 0s 884us/step - loss: 2.4233 - sparse_categorical_accuracy: 0.2469 - val_loss: 2.3766 - val_sparse_categorical_accuracy: 0.2087\n",
      "Epoch 2/20\n",
      "232/232 [==============================] - 0s 759us/step - loss: 2.0182 - sparse_categorical_accuracy: 0.3191 - val_loss: 2.4397 - val_sparse_categorical_accuracy: 0.1890\n",
      "Epoch 3/20\n",
      "232/232 [==============================] - 0s 754us/step - loss: 1.8660 - sparse_categorical_accuracy: 0.3509 - val_loss: 2.5956 - val_sparse_categorical_accuracy: 0.2028\n",
      "Epoch 4/20\n",
      "232/232 [==============================] - 0s 746us/step - loss: 1.6995 - sparse_categorical_accuracy: 0.4205 - val_loss: 2.5933 - val_sparse_categorical_accuracy: 0.1752\n",
      "Epoch 5/20\n",
      "232/232 [==============================] - 0s 716us/step - loss: 1.5141 - sparse_categorical_accuracy: 0.4836 - val_loss: 2.6886 - val_sparse_categorical_accuracy: 0.1673\n",
      "Epoch 6/20\n",
      "232/232 [==============================] - 0s 759us/step - loss: 1.3511 - sparse_categorical_accuracy: 0.5175 - val_loss: 2.9845 - val_sparse_categorical_accuracy: 0.1614\n",
      "Epoch 7/20\n",
      "232/232 [==============================] - 0s 703us/step - loss: 1.1421 - sparse_categorical_accuracy: 0.5919 - val_loss: 3.1182 - val_sparse_categorical_accuracy: 0.1772\n",
      "Epoch 8/20\n",
      "232/232 [==============================] - 0s 728us/step - loss: 0.9886 - sparse_categorical_accuracy: 0.6512 - val_loss: 3.6383 - val_sparse_categorical_accuracy: 0.1693\n",
      "Epoch 9/20\n",
      "232/232 [==============================] - 0s 711us/step - loss: 0.7993 - sparse_categorical_accuracy: 0.7154 - val_loss: 3.9887 - val_sparse_categorical_accuracy: 0.1949\n",
      "Epoch 10/20\n",
      "232/232 [==============================] - 0s 733us/step - loss: 0.6470 - sparse_categorical_accuracy: 0.7801 - val_loss: 4.2018 - val_sparse_categorical_accuracy: 0.1634\n",
      "Epoch 11/20\n",
      "232/232 [==============================] - 0s 711us/step - loss: 0.5656 - sparse_categorical_accuracy: 0.8032 - val_loss: 4.3029 - val_sparse_categorical_accuracy: 0.1988\n",
      "Epoch 12/20\n",
      "232/232 [==============================] - 0s 707us/step - loss: 0.5081 - sparse_categorical_accuracy: 0.8270 - val_loss: 4.6793 - val_sparse_categorical_accuracy: 0.1555\n",
      "Epoch 13/20\n",
      "232/232 [==============================] - 0s 802us/step - loss: 0.4227 - sparse_categorical_accuracy: 0.8507 - val_loss: 5.0053 - val_sparse_categorical_accuracy: 0.1398\n",
      "Epoch 14/20\n",
      "232/232 [==============================] - 0s 853us/step - loss: 0.3595 - sparse_categorical_accuracy: 0.8782 - val_loss: 5.9879 - val_sparse_categorical_accuracy: 0.1437\n",
      "Epoch 15/20\n",
      "232/232 [==============================] - 0s 802us/step - loss: 0.3153 - sparse_categorical_accuracy: 0.8965 - val_loss: 5.3934 - val_sparse_categorical_accuracy: 0.1752\n",
      "Epoch 16/20\n",
      "232/232 [==============================] - 0s 703us/step - loss: 0.3625 - sparse_categorical_accuracy: 0.8755 - val_loss: 5.7667 - val_sparse_categorical_accuracy: 0.1358\n",
      "Epoch 17/20\n",
      "232/232 [==============================] - 0s 703us/step - loss: 0.2970 - sparse_categorical_accuracy: 0.9008 - val_loss: 5.8323 - val_sparse_categorical_accuracy: 0.1417\n",
      "Epoch 18/20\n",
      "232/232 [==============================] - 0s 793us/step - loss: 0.2889 - sparse_categorical_accuracy: 0.9008 - val_loss: 6.5580 - val_sparse_categorical_accuracy: 0.1634\n",
      "Epoch 19/20\n",
      "232/232 [==============================] - 0s 797us/step - loss: 0.2460 - sparse_categorical_accuracy: 0.9143 - val_loss: 6.9155 - val_sparse_categorical_accuracy: 0.1535\n",
      "Epoch 20/20\n",
      "232/232 [==============================] - 0s 789us/step - loss: 0.2375 - sparse_categorical_accuracy: 0.9186 - val_loss: 7.0630 - val_sparse_categorical_accuracy: 0.1457\n",
      "64/64 [==============================] - 0s 406us/step - loss: 7.0630 - sparse_categorical_accuracy: 0.1457\n"
     ]
    }
   ],
   "source": [
    "dense3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "history = compile_and_fit(dense3, another_window)\n",
    "\n",
    "val_performance = dense3.evaluate(another_window.val)\n",
    "performance = dense3.evaluate(another_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "CONV_WIDTH = 10\n",
    "conv_window = WindowGenerator(\n",
    "    input_width=CONV_WIDTH,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    label_columns=['cat_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 2.2307 - sparse_categorical_accuracy: 0.2616 - val_loss: 2.2304 - val_sparse_categorical_accuracy: 0.2358\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 0s 770us/step - loss: 1.9956 - sparse_categorical_accuracy: 0.3335 - val_loss: 2.1990 - val_sparse_categorical_accuracy: 0.2340\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 0s 783us/step - loss: 1.8728 - sparse_categorical_accuracy: 0.3596 - val_loss: 2.2241 - val_sparse_categorical_accuracy: 0.2226\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 0s 770us/step - loss: 1.7822 - sparse_categorical_accuracy: 0.3889 - val_loss: 2.2195 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 0s 826us/step - loss: 1.7092 - sparse_categorical_accuracy: 0.4012 - val_loss: 2.2309 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 0s 757us/step - loss: 1.6354 - sparse_categorical_accuracy: 0.4321 - val_loss: 2.3054 - val_sparse_categorical_accuracy: 0.2245\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 0s 915us/step - loss: 1.5457 - sparse_categorical_accuracy: 0.4587 - val_loss: 2.2942 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 0s 804us/step - loss: 1.4558 - sparse_categorical_accuracy: 0.4912 - val_loss: 2.4181 - val_sparse_categorical_accuracy: 0.2151\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 0s 813us/step - loss: 1.3799 - sparse_categorical_accuracy: 0.4955 - val_loss: 2.5687 - val_sparse_categorical_accuracy: 0.2057\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 0s 847us/step - loss: 1.2901 - sparse_categorical_accuracy: 0.5354 - val_loss: 2.6324 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 0s 762us/step - loss: 1.1908 - sparse_categorical_accuracy: 0.5786 - val_loss: 2.8141 - val_sparse_categorical_accuracy: 0.2094\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 0s 821us/step - loss: 1.0864 - sparse_categorical_accuracy: 0.6026 - val_loss: 3.1623 - val_sparse_categorical_accuracy: 0.2151\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 0s 766us/step - loss: 0.9772 - sparse_categorical_accuracy: 0.6532 - val_loss: 3.3069 - val_sparse_categorical_accuracy: 0.2189\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 0s 847us/step - loss: 0.8737 - sparse_categorical_accuracy: 0.6739 - val_loss: 3.7489 - val_sparse_categorical_accuracy: 0.2321\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7928 - sparse_categorical_accuracy: 0.7075 - val_loss: 3.8905 - val_sparse_categorical_accuracy: 0.2170\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 0s 877us/step - loss: 0.6785 - sparse_categorical_accuracy: 0.7619 - val_loss: 4.4768 - val_sparse_categorical_accuracy: 0.2340\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 0s 838us/step - loss: 0.6192 - sparse_categorical_accuracy: 0.7794 - val_loss: 4.3753 - val_sparse_categorical_accuracy: 0.2396\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 0s 826us/step - loss: 0.5341 - sparse_categorical_accuracy: 0.8071 - val_loss: 5.0857 - val_sparse_categorical_accuracy: 0.2208\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 0s 847us/step - loss: 0.4768 - sparse_categorical_accuracy: 0.8258 - val_loss: 5.3347 - val_sparse_categorical_accuracy: 0.2264\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 0s 826us/step - loss: 0.4411 - sparse_categorical_accuracy: 0.8460 - val_loss: 5.6483 - val_sparse_categorical_accuracy: 0.2321\n",
      "67/67 [==============================] - 0s 463us/step - loss: 5.6483 - sparse_categorical_accuracy: 0.2321\n"
     ]
    }
   ],
   "source": [
    "conv_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32,\n",
    "                           kernel_size=(CONV_WIDTH,),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=vocab_size)\n",
    "])\n",
    "\n",
    "\n",
    "history = compile_and_fit(conv_model, conv_window)\n",
    "\n",
    "val_performance = conv_model.evaluate(conv_window.val)\n",
    "performance = conv_model.evaluate(conv_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Total window size: 9\nInput indices: [0 1 2 3 4 5 6 7]\nLabel indices: [8]\nLabel column name(s): ['cat_id']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_3 = WindowGenerator(\n",
    "    input_width=8, label_width=1, shift=1,\n",
    "    label_columns=['cat_id'])\n",
    "\n",
    "window_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorSpec(shape=(None, 8, 9), dtype=tf.float32, name=None),\n TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each element is an (inputs, label) pair.\n",
    "window_3.train.element_spec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.4130 - sparse_categorical_accuracy: 0.2437 - val_loss: 2.2554 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1828 - sparse_categorical_accuracy: 0.2885 - val_loss: 2.2440 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.1019 - sparse_categorical_accuracy: 0.3007 - val_loss: 2.2223 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.0531 - sparse_categorical_accuracy: 0.3113 - val_loss: 2.1922 - val_sparse_categorical_accuracy: 0.2481\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 2.0140 - sparse_categorical_accuracy: 0.3124 - val_loss: 2.1794 - val_sparse_categorical_accuracy: 0.2256\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.9880 - sparse_categorical_accuracy: 0.3252 - val_loss: 2.1723 - val_sparse_categorical_accuracy: 0.2350\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.9314 - sparse_categorical_accuracy: 0.3438 - val_loss: 2.1544 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.9123 - sparse_categorical_accuracy: 0.3363 - val_loss: 2.1386 - val_sparse_categorical_accuracy: 0.2350\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8761 - sparse_categorical_accuracy: 0.3566 - val_loss: 2.1507 - val_sparse_categorical_accuracy: 0.2425\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8401 - sparse_categorical_accuracy: 0.3592 - val_loss: 2.1405 - val_sparse_categorical_accuracy: 0.2425\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.7776 - sparse_categorical_accuracy: 0.3741 - val_loss: 2.1480 - val_sparse_categorical_accuracy: 0.2387\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.7372 - sparse_categorical_accuracy: 0.3896 - val_loss: 2.1715 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6985 - sparse_categorical_accuracy: 0.4039 - val_loss: 2.3201 - val_sparse_categorical_accuracy: 0.2613\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6547 - sparse_categorical_accuracy: 0.4093 - val_loss: 2.2176 - val_sparse_categorical_accuracy: 0.2575\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6141 - sparse_categorical_accuracy: 0.4188 - val_loss: 2.2623 - val_sparse_categorical_accuracy: 0.2575\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.5876 - sparse_categorical_accuracy: 0.4305 - val_loss: 2.3415 - val_sparse_categorical_accuracy: 0.2632\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.5432 - sparse_categorical_accuracy: 0.4561 - val_loss: 2.4642 - val_sparse_categorical_accuracy: 0.2763\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 1.4864 - sparse_categorical_accuracy: 0.4774 - val_loss: 2.5275 - val_sparse_categorical_accuracy: 0.2387\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.4665 - sparse_categorical_accuracy: 0.4715 - val_loss: 2.4595 - val_sparse_categorical_accuracy: 0.2744\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.4210 - sparse_categorical_accuracy: 0.4870 - val_loss: 2.6274 - val_sparse_categorical_accuracy: 0.2481\n",
      "67/67 [==============================] - 0s 955us/step - loss: 2.6274 - sparse_categorical_accuracy: 0.2481\n"
     ]
    }
   ],
   "source": [
    "lstm = tf.keras.Sequential()\n",
    "lstm.add(tf.keras.layers.LSTM(128,return_sequences=True,input_shape=(8, 9), activation='relu'))\n",
    "lstm.add(tf.keras.layers.LSTM(64,input_shape=(8, 9), activation='relu'))\n",
    "lstm.add(tf.keras.layers.Dropout(0.5))\n",
    "lstm.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "history = compile_and_fit(lstm, window_3)\n",
    "\n",
    "val_performance = lstm.evaluate(window_3.val)\n",
    "performance = lstm.evaluate(window_3.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.4007 - sparse_categorical_accuracy: 0.2576 - val_loss: 2.2953 - val_sparse_categorical_accuracy: 0.2444\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.1227 - sparse_categorical_accuracy: 0.2906 - val_loss: 2.1800 - val_sparse_categorical_accuracy: 0.2425\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 2.0210 - sparse_categorical_accuracy: 0.3321 - val_loss: 2.1677 - val_sparse_categorical_accuracy: 0.2556\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.9482 - sparse_categorical_accuracy: 0.3363 - val_loss: 2.1346 - val_sparse_categorical_accuracy: 0.2594\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8953 - sparse_categorical_accuracy: 0.3513 - val_loss: 2.1367 - val_sparse_categorical_accuracy: 0.2669\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.8426 - sparse_categorical_accuracy: 0.3699 - val_loss: 2.1546 - val_sparse_categorical_accuracy: 0.2669\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.7736 - sparse_categorical_accuracy: 0.3938 - val_loss: 2.1479 - val_sparse_categorical_accuracy: 0.2726\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.7136 - sparse_categorical_accuracy: 0.4156 - val_loss: 2.1234 - val_sparse_categorical_accuracy: 0.2782\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6843 - sparse_categorical_accuracy: 0.4162 - val_loss: 2.1151 - val_sparse_categorical_accuracy: 0.2744\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.6236 - sparse_categorical_accuracy: 0.4428 - val_loss: 2.1349 - val_sparse_categorical_accuracy: 0.2688\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.5704 - sparse_categorical_accuracy: 0.4524 - val_loss: 2.2043 - val_sparse_categorical_accuracy: 0.2688\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.5199 - sparse_categorical_accuracy: 0.4768 - val_loss: 2.2467 - val_sparse_categorical_accuracy: 0.2707\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.4505 - sparse_categorical_accuracy: 0.4880 - val_loss: 2.3202 - val_sparse_categorical_accuracy: 0.2650\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.3958 - sparse_categorical_accuracy: 0.5008 - val_loss: 2.2937 - val_sparse_categorical_accuracy: 0.2650\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.3842 - sparse_categorical_accuracy: 0.5290 - val_loss: 2.3714 - val_sparse_categorical_accuracy: 0.2462\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.3197 - sparse_categorical_accuracy: 0.5439 - val_loss: 2.4468 - val_sparse_categorical_accuracy: 0.2782\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.2715 - sparse_categorical_accuracy: 0.5444 - val_loss: 2.5982 - val_sparse_categorical_accuracy: 0.2556\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.1986 - sparse_categorical_accuracy: 0.5764 - val_loss: 2.8690 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.1578 - sparse_categorical_accuracy: 0.5716 - val_loss: 2.9133 - val_sparse_categorical_accuracy: 0.2500\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.1040 - sparse_categorical_accuracy: 0.6046 - val_loss: 2.9274 - val_sparse_categorical_accuracy: 0.2650\n",
      "67/67 [==============================] - 0s 925us/step - loss: 2.9274 - sparse_categorical_accuracy: 0.2650\n"
     ]
    }
   ],
   "source": [
    "gru1 = tf.keras.Sequential()\n",
    "gru1.add(tf.keras.layers.GRU(128,return_sequences=True,input_shape=(8, 9), activation='relu'))\n",
    "gru1.add(tf.keras.layers.GRU(64,input_shape=(8, 9), activation='relu'))\n",
    "gru1.add(tf.keras.layers.Dropout(0.5))\n",
    "gru1.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "history = compile_and_fit(gru1, window_3)\n",
    "\n",
    "val_performance = gru1.evaluate(window_3.val)\n",
    "performance = gru1.evaluate(window_3.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 2.4968 - sparse_categorical_accuracy: 0.2333 - val_loss: 2.2547 - val_sparse_categorical_accuracy: 0.2301\n",
      "Epoch 2/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.1330 - sparse_categorical_accuracy: 0.2847 - val_loss: 2.1773 - val_sparse_categorical_accuracy: 0.2430\n",
      "Epoch 3/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.0627 - sparse_categorical_accuracy: 0.2959 - val_loss: 2.1671 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 4/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 2.0167 - sparse_categorical_accuracy: 0.2948 - val_loss: 2.1752 - val_sparse_categorical_accuracy: 0.2393\n",
      "Epoch 5/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.9738 - sparse_categorical_accuracy: 0.3277 - val_loss: 2.1985 - val_sparse_categorical_accuracy: 0.2486\n",
      "Epoch 6/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.9285 - sparse_categorical_accuracy: 0.3319 - val_loss: 2.1575 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 7/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.9118 - sparse_categorical_accuracy: 0.3324 - val_loss: 2.1497 - val_sparse_categorical_accuracy: 0.2579\n",
      "Epoch 8/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8712 - sparse_categorical_accuracy: 0.3515 - val_loss: 2.1791 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 9/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8578 - sparse_categorical_accuracy: 0.3637 - val_loss: 2.1521 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 10/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8407 - sparse_categorical_accuracy: 0.3584 - val_loss: 2.1610 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 11/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8119 - sparse_categorical_accuracy: 0.3918 - val_loss: 2.1577 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 12/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.8170 - sparse_categorical_accuracy: 0.3558 - val_loss: 2.1554 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 13/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7775 - sparse_categorical_accuracy: 0.3892 - val_loss: 2.1389 - val_sparse_categorical_accuracy: 0.2542\n",
      "Epoch 14/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7638 - sparse_categorical_accuracy: 0.3892 - val_loss: 2.1956 - val_sparse_categorical_accuracy: 0.2597\n",
      "Epoch 15/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7473 - sparse_categorical_accuracy: 0.3786 - val_loss: 2.1785 - val_sparse_categorical_accuracy: 0.2709\n",
      "Epoch 16/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7401 - sparse_categorical_accuracy: 0.3918 - val_loss: 2.1998 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 17/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7380 - sparse_categorical_accuracy: 0.3849 - val_loss: 2.1868 - val_sparse_categorical_accuracy: 0.2486\n",
      "Epoch 18/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7148 - sparse_categorical_accuracy: 0.3966 - val_loss: 2.1973 - val_sparse_categorical_accuracy: 0.2560\n",
      "Epoch 19/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7033 - sparse_categorical_accuracy: 0.3849 - val_loss: 2.2162 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 20/20\n",
      "236/236 [==============================] - 0s 1ms/step - loss: 1.7090 - sparse_categorical_accuracy: 0.3860 - val_loss: 2.1519 - val_sparse_categorical_accuracy: 0.2672\n",
      "68/68 [==============================] - 0s 529us/step - loss: 2.1519 - sparse_categorical_accuracy: 0.2672\n"
     ]
    }
   ],
   "source": [
    "gru2 = tf.keras.Sequential()\n",
    "gru2.add(tf.keras.layers.GRU(128,return_sequences=True,input_shape=(1, 9), activation='relu'))\n",
    "gru2.add(tf.keras.layers.GRU(64,input_shape=(1, 9), activation='relu'))\n",
    "gru2.add(tf.keras.layers.Dropout(0.5))\n",
    "gru2.add(tf.keras.layers.Dense(vocab_size))\n",
    "\n",
    "history = compile_and_fit(gru2, single_step_window)\n",
    "\n",
    "val_performance = gru2.evaluate(single_step_window.val)\n",
    "performance = gru2.evaluate(single_step_window.test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}