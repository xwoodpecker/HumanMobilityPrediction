{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Central Model Evaluation Part 3\n",
    "\n",
    "The central model is evaluated for the cincinnati dataset.\n",
    "Part 3 is used as a comparison for the flower federated learning approach.\n",
    "Here, a test was executed on Raspberry Pis as physical clients.\n",
    "The data was federated and trained on them.\n",
    "The same data partition is to be trained on in this model with a similar model architecture."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model_helper.ipynb\n"
     ]
    }
   ],
   "source": [
    "from model_helper import ModelHelper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataSet\n",
    "\n",
    "This time, only the zones used in the physical test with flowers are used for training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   location_id  vehicle_id  is_weekend  clock_sin  clock_cos   day_sin  \\\n0            0         116       False   0.948254  -0.317512  0.994522   \n1            1         457       False   0.902523  -0.430642  0.406737   \n2            2         153       False   0.382415  -0.923991 -0.994522   \n3            3         215       False   0.960030  -0.279899 -0.587785   \n4            1         303       False   0.065040  -0.997883  0.743145   \n5            4         107        True   0.852564  -0.522623  0.994522   \n6            1         383       False   0.949608  -0.313440  0.951057   \n7            5         130       False   0.894934  -0.446198 -0.951057   \n8            2         445       False   0.169350  -0.985556 -0.406737   \n9            4         457       False   0.533492  -0.845805 -0.207912   \n\n    day_cos  month_sin  month_cos  week_day_sin  week_day_cos  \n0 -0.104528   0.500000   0.866025      0.974928     -0.222521  \n1  0.913545   0.500000   0.866025      0.433884     -0.900969  \n2 -0.104528   0.500000   0.866025      0.974928     -0.222521  \n3 -0.809017   0.866025   0.500000      0.781831      0.623490  \n4  0.669131   0.866025   0.500000      0.781831      0.623490  \n5 -0.104528   0.866025   0.500000     -0.974928     -0.222521  \n6  0.309017   0.866025   0.500000      0.433884     -0.900969  \n7 -0.309017   0.500000   0.866025      0.781831      0.623490  \n8 -0.913545   0.500000   0.866025     -0.433884     -0.900969  \n9  0.978148   0.500000   0.866025      0.974928     -0.222521  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location_id</th>\n      <th>vehicle_id</th>\n      <th>is_weekend</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>116</td>\n      <td>False</td>\n      <td>0.948254</td>\n      <td>-0.317512</td>\n      <td>0.994522</td>\n      <td>-0.104528</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>457</td>\n      <td>False</td>\n      <td>0.902523</td>\n      <td>-0.430642</td>\n      <td>0.406737</td>\n      <td>0.913545</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>153</td>\n      <td>False</td>\n      <td>0.382415</td>\n      <td>-0.923991</td>\n      <td>-0.994522</td>\n      <td>-0.104528</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>215</td>\n      <td>False</td>\n      <td>0.960030</td>\n      <td>-0.279899</td>\n      <td>-0.587785</td>\n      <td>-0.809017</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>303</td>\n      <td>False</td>\n      <td>0.065040</td>\n      <td>-0.997883</td>\n      <td>0.743145</td>\n      <td>0.669131</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>107</td>\n      <td>True</td>\n      <td>0.852564</td>\n      <td>-0.522623</td>\n      <td>0.994522</td>\n      <td>-0.104528</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>383</td>\n      <td>False</td>\n      <td>0.949608</td>\n      <td>-0.313440</td>\n      <td>0.951057</td>\n      <td>0.309017</td>\n      <td>0.866025</td>\n      <td>0.500000</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5</td>\n      <td>130</td>\n      <td>False</td>\n      <td>0.894934</td>\n      <td>-0.446198</td>\n      <td>-0.951057</td>\n      <td>-0.309017</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>445</td>\n      <td>False</td>\n      <td>0.169350</td>\n      <td>-0.985556</td>\n      <td>-0.406737</td>\n      <td>-0.913545</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>457</td>\n      <td>False</td>\n      <td>0.533492</td>\n      <td>-0.845805</td>\n      <td>-0.207912</td>\n      <td>0.978148</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./cincinnati/cincinatti_zones.csv\")\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 100\n"
     ]
    }
   ],
   "source": [
    "# the number of different locations defines the vocabulary size\n",
    "locations = df.location_id\n",
    "vocab_size = locations.nunique()\n",
    "\n",
    "print('vocabulary size:', vocab_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Init the ModelHelper and set all needed parameters such as the different column_names and the vocab_size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mh = ModelHelper(df, 17)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset is limited to only include two different client_ids.\n",
    "This way the results between this centralized model and the model trained by flower are comparable.\n",
    "It was only managed to get flower working on two Raspberry PIs, therefor only two clients are chosen.\n",
    "This is expected to significantly impact the performance of the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "mh.set_target_column_name('location_id')\n",
    "mh.set_vocab_size(vocab_size)\n",
    "\n",
    "numerical_column_names = ['clock_sin', 'clock_cos', 'day_sin', 'day_cos', 'month_sin', 'month_cos', 'week_day_sin', 'week_day_cos']\n",
    "column_names = ['location_id'] + numerical_column_names\n",
    "mh.set_column_names(column_names)\n",
    "mh.set_numerical_column_names(numerical_column_names)\n",
    "\n",
    "mh.set_client_column_name('vehicle_id')\n",
    "CLIENT_IDS = [457, 461]\n",
    "mh.set_client_column_ids(CLIENT_IDS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "count = df.vehicle_id.value_counts()\n",
    "\n",
    "idx = count.loc[count.index[:100]].index # count >= 100\n",
    "df = df.loc[df.vehicle_id.isin(idx)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An array is created containing all visited locations for every user.\n",
    "The original data is sorted by time (ascending).\n",
    "Thus, the array contains a sequence of visited locations by user."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 11.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[          location_id  vehicle_id  is_weekend  clock_sin  clock_cos   day_sin  \\\n 1                   1         457       False   0.902523  -0.430642  0.406737   \n 9                   4         457       False   0.533492  -0.845805 -0.207912   \n 123                 4         457       False   0.796002  -0.605294  0.866025   \n 124                 2         457       False   0.678534  -0.734569 -0.587785   \n 143                 1         457       False  -0.492550  -0.870284  0.207912   \n ...               ...         ...         ...        ...        ...       ...   \n 19073749            2         457       False  -0.469600  -0.882879  0.406737   \n 19073823            1         457       False  -0.030611  -0.999531  0.866025   \n 19074051            6         457       False  -0.485128  -0.874443 -0.743145   \n 19074159            2         457       False  -0.241922  -0.970296 -0.207912   \n 19074203            1         457       False  -0.030902  -0.999522  0.951057   \n \n            day_cos     month_sin  month_cos  week_day_sin  week_day_cos  \n 1         0.913545  5.000000e-01   0.866025      0.433884     -0.900969  \n 9         0.978148  5.000000e-01   0.866025      0.974928     -0.222521  \n 123       0.500000  8.660254e-01   0.500000      0.974928     -0.222521  \n 124       0.809017  5.000000e-01   0.866025      0.000000      1.000000  \n 143      -0.978148  5.000000e-01   0.866025      0.781831      0.623490  \n ...            ...           ...        ...           ...           ...  \n 19073749  0.913545 -5.000000e-01   0.866025      0.000000      1.000000  \n 19073823 -0.500000 -2.449294e-16   1.000000      0.433884     -0.900969  \n 19074051 -0.669131 -8.660254e-01   0.500000      0.000000      1.000000  \n 19074159 -0.978148 -8.660254e-01   0.500000     -0.433884     -0.900969  \n 19074203 -0.309017 -2.449294e-16   1.000000      0.974928     -0.222521  \n \n [388716 rows x 11 columns],\n           location_id  vehicle_id  is_weekend  clock_sin  clock_cos   day_sin  \\\n 211                18         461       False   0.779793  -0.626037 -0.743145   \n 271                 9         461       False  -0.096208  -0.995361 -0.406737   \n 283                19         461       False   0.608473  -0.793575  0.743145   \n 412                18         461       False  -0.074181  -0.997245  0.866025   \n 503                 2         461       False   0.254250  -0.967138 -0.994522   \n ...               ...         ...         ...        ...        ...       ...   \n 19073892           18         461       False   0.511293  -0.859406  0.207912   \n 19073933            2         461       False   0.559133  -0.829078 -0.207912   \n 19073952            1         461       False   0.662348  -0.749197  0.866025   \n 19074001           23         461       False  -0.043765  -0.999042  0.866025   \n 19074112            6         461       False   0.774393  -0.632705  0.866025   \n \n            day_cos     month_sin     month_cos  week_day_sin  week_day_cos  \n 211       0.669131  8.660254e-01  5.000000e-01      0.974928     -0.222521  \n 271      -0.913545  1.000000e+00  6.123234e-17      0.781831      0.623490  \n 283      -0.669131  8.660254e-01  5.000000e-01      0.781831      0.623490  \n 412       0.500000  8.660254e-01  5.000000e-01      0.974928     -0.222521  \n 503      -0.104528  5.000000e-01  8.660254e-01      0.974928     -0.222521  \n ...            ...           ...           ...           ...           ...  \n 19073892  0.978148 -2.449294e-16  1.000000e+00      0.781831      0.623490  \n 19073933 -0.978148 -5.000000e-01  8.660254e-01      0.000000      1.000000  \n 19073952 -0.500000 -2.449294e-16  1.000000e+00      0.433884     -0.900969  \n 19074001  0.500000 -8.660254e-01  5.000000e-01      0.000000      1.000000  \n 19074112 -0.500000 -5.000000e-01  8.660254e-01      0.781831      0.623490  \n \n [300924 rows x 11 columns]]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.create_users_locations_from_df()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is necessary to first split the data in train, valid and test for each user.\n",
    "Then, these are merged together again later on.\n",
    "This is done to ensure that the sequences are kept together and not split randomly for the users."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "mh.concat_split_users_locations()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441368 train examples\n",
      "110343 validation examples\n",
      "137929 test examples\n"
     ]
    }
   ],
   "source": [
    "print(len(mh.df_train), 'train examples')\n",
    "print(len(mh.df_val), 'validation examples')\n",
    "print(len(mh.df_test), 'test examples')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data and create the batch datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8114\n"
     ]
    },
    {
     "data": {
      "text/plain": "          location_id  is_weekend  clock_sin  clock_cos       day_sin  \\\n13247969            1       False   0.850237  -0.526399  4.067366e-01   \n13248042           25       False   0.156147  -0.987734  2.079117e-01   \n13248048            1       False   0.870356  -0.492424 -1.133108e-15   \n13248053            2       False   0.697738  -0.716353  4.067366e-01   \n13248067            4       False   0.138813  -0.990319  9.510565e-01   \n13248098            2       False   0.245801  -0.969320 -4.067366e-01   \n13248114           29       False  -0.526276  -0.850314 -1.133108e-15   \n13248136            7       False  -0.263242  -0.964730 -8.660254e-01   \n13248265           25       False  -0.386711  -0.922201 -4.067366e-01   \n13248274           10       False   0.349935  -0.936774  9.510565e-01   \n13248280            2       False   0.615432  -0.788190  9.510565e-01   \n13248285           20       False   0.706952  -0.707261  9.945219e-01   \n13248340           19       False  -0.108867  -0.994056  9.510565e-01   \n13248371            1       False   0.892979  -0.450098 -8.660254e-01   \n13248393           19       False  -0.241922  -0.970296 -8.660254e-01   \n13248484            4       False  -0.026250  -0.999655  5.877853e-01   \n13248493           16       False   0.275288  -0.961362  2.079117e-01   \n\n           day_cos  month_sin     month_cos  week_day_sin  week_day_cos  \n13247969  0.913545  -1.000000 -1.836970e-16      0.974928     -0.222521  \n13248042 -0.978148  -0.500000 -8.660254e-01      0.781831      0.623490  \n13248048  1.000000  -0.500000 -8.660254e-01      0.433884     -0.900969  \n13248053 -0.913545  -0.500000 -8.660254e-01      0.000000      1.000000  \n13248067 -0.309017  -0.500000 -8.660254e-01      0.433884     -0.900969  \n13248098 -0.913545  -1.000000 -1.836970e-16      0.433884     -0.900969  \n13248114  1.000000  -1.000000 -1.836970e-16      0.974928     -0.222521  \n13248136 -0.500000  -0.866025 -5.000000e-01      0.433884     -0.900969  \n13248265 -0.913545  -0.866025 -5.000000e-01      0.000000      1.000000  \n13248274  0.309017  -0.500000 -8.660254e-01      0.000000      1.000000  \n13248280  0.309017  -0.866025 -5.000000e-01      0.433884     -0.900969  \n13248285 -0.104528  -0.500000 -8.660254e-01      0.974928     -0.222521  \n13248340 -0.309017  -1.000000 -1.836970e-16      0.974928     -0.222521  \n13248371 -0.500000  -0.500000 -8.660254e-01      0.000000      1.000000  \n13248393 -0.500000  -0.500000 -8.660254e-01      0.000000      1.000000  \n13248484  0.809017  -0.866025 -5.000000e-01      0.000000      1.000000  \n13248493 -0.978148  -0.866025 -5.000000e-01     -0.433884     -0.900969  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location_id</th>\n      <th>is_weekend</th>\n      <th>clock_sin</th>\n      <th>clock_cos</th>\n      <th>day_sin</th>\n      <th>day_cos</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13247969</th>\n      <td>1</td>\n      <td>False</td>\n      <td>0.850237</td>\n      <td>-0.526399</td>\n      <td>4.067366e-01</td>\n      <td>0.913545</td>\n      <td>-1.000000</td>\n      <td>-1.836970e-16</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>13248042</th>\n      <td>25</td>\n      <td>False</td>\n      <td>0.156147</td>\n      <td>-0.987734</td>\n      <td>2.079117e-01</td>\n      <td>-0.978148</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>13248048</th>\n      <td>1</td>\n      <td>False</td>\n      <td>0.870356</td>\n      <td>-0.492424</td>\n      <td>-1.133108e-15</td>\n      <td>1.000000</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13248053</th>\n      <td>2</td>\n      <td>False</td>\n      <td>0.697738</td>\n      <td>-0.716353</td>\n      <td>4.067366e-01</td>\n      <td>-0.913545</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13248067</th>\n      <td>4</td>\n      <td>False</td>\n      <td>0.138813</td>\n      <td>-0.990319</td>\n      <td>9.510565e-01</td>\n      <td>-0.309017</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13248098</th>\n      <td>2</td>\n      <td>False</td>\n      <td>0.245801</td>\n      <td>-0.969320</td>\n      <td>-4.067366e-01</td>\n      <td>-0.913545</td>\n      <td>-1.000000</td>\n      <td>-1.836970e-16</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13248114</th>\n      <td>29</td>\n      <td>False</td>\n      <td>-0.526276</td>\n      <td>-0.850314</td>\n      <td>-1.133108e-15</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.836970e-16</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>13248136</th>\n      <td>7</td>\n      <td>False</td>\n      <td>-0.263242</td>\n      <td>-0.964730</td>\n      <td>-8.660254e-01</td>\n      <td>-0.500000</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13248265</th>\n      <td>25</td>\n      <td>False</td>\n      <td>-0.386711</td>\n      <td>-0.922201</td>\n      <td>-4.067366e-01</td>\n      <td>-0.913545</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13248274</th>\n      <td>10</td>\n      <td>False</td>\n      <td>0.349935</td>\n      <td>-0.936774</td>\n      <td>9.510565e-01</td>\n      <td>0.309017</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13248280</th>\n      <td>2</td>\n      <td>False</td>\n      <td>0.615432</td>\n      <td>-0.788190</td>\n      <td>9.510565e-01</td>\n      <td>0.309017</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>13248285</th>\n      <td>20</td>\n      <td>False</td>\n      <td>0.706952</td>\n      <td>-0.707261</td>\n      <td>9.945219e-01</td>\n      <td>-0.104528</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>13248340</th>\n      <td>19</td>\n      <td>False</td>\n      <td>-0.108867</td>\n      <td>-0.994056</td>\n      <td>9.510565e-01</td>\n      <td>-0.309017</td>\n      <td>-1.000000</td>\n      <td>-1.836970e-16</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>13248371</th>\n      <td>1</td>\n      <td>False</td>\n      <td>0.892979</td>\n      <td>-0.450098</td>\n      <td>-8.660254e-01</td>\n      <td>-0.500000</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13248393</th>\n      <td>19</td>\n      <td>False</td>\n      <td>-0.241922</td>\n      <td>-0.970296</td>\n      <td>-8.660254e-01</td>\n      <td>-0.500000</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13248484</th>\n      <td>4</td>\n      <td>False</td>\n      <td>-0.026250</td>\n      <td>-0.999655</td>\n      <td>5.877853e-01</td>\n      <td>0.809017</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13248493</th>\n      <td>16</td>\n      <td>False</td>\n      <td>0.275288</td>\n      <td>-0.961362</td>\n      <td>2.079117e-01</td>\n      <td>-0.978148</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mh.split_data_sliding()\n",
    "mh.split_data()\n",
    "print(len(mh.list_test))\n",
    "mh.list_test[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "mh.set_batch_size(16)\n",
    "mh.create_and_batch_datasets(multi_target=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units1 = 256\n",
    "rnn_units2 = 128\n",
    "\n",
    "# Create a model\n",
    "def create_keras_model():\n",
    "  N = mh.total_window_length\n",
    "  batch_size = mh.batch_size\n",
    "  number_of_places = mh.vocab_size\n",
    "\n",
    "  # Shortcut to the layers package\n",
    "  l = tf.keras.layers\n",
    "\n",
    "  # List of numeric feature columns to pass to the DenseLayer\n",
    "  numeric_feature_columns = []\n",
    "\n",
    "  # Handling numerical columns\n",
    "  for header in numerical_column_names:\n",
    "\t# Append all the numerical columns defined into the list\n",
    "    numeric_feature_columns.append(feature_column.numeric_column(header, shape=N-1))\n",
    "\n",
    "  feature_inputs={}\n",
    "  for c_name in numerical_column_names:\n",
    "    feature_inputs[c_name] = tf.keras.Input((N-1,), batch_size=batch_size, name=c_name)\n",
    "\n",
    "  # We cannot use an array of features as always because we have sequences\n",
    "  # We have to do one by one in order to match the shape\n",
    "  num_features = []\n",
    "  for c_name in numerical_column_names:\n",
    "    f =  feature_column.numeric_column(c_name, shape=(N-1))\n",
    "    feature = l.DenseFeatures(f)(feature_inputs)\n",
    "    feature = tf.expand_dims(feature, -1)\n",
    "    num_features.append(feature)\n",
    "\n",
    "  # Declare the dictionary for the locations sequence as before\n",
    "  sequence_input = {\n",
    "      'location_id': tf.keras.Input((N-1,), batch_size=batch_size, dtype=tf.dtypes.int32, name='location_id') # add batch_size=batch_size in case of stateful GRU\n",
    "  }\n",
    "\n",
    "  # Handling the categorical feature sequence using one-hot\n",
    "  location_one_hot = feature_column.sequence_categorical_column_with_vocabulary_list(\n",
    "      'location_id', [i for i in range(number_of_places)])\n",
    "\n",
    "  # one-hot encoding\n",
    "  location_feature = feature_column.embedding_column(location_one_hot, embedding_dim)\n",
    "\n",
    "  # With an input sequence we can't use the DenseFeature layer, we need to use the SequenceFeatures\n",
    "  sequence_features, sequence_length = tf.keras.experimental.SequenceFeatures(location_feature)(sequence_input)\n",
    "\n",
    "\n",
    "  input_sequence = l.Concatenate(axis=2)([sequence_features] + num_features)\n",
    "\n",
    "  # Rnn\n",
    "  recurrent = l.GRU(rnn_units1,\n",
    "                    batch_size=batch_size, #in case of stateful\n",
    "                    return_sequences=True,\n",
    "                    stateful=True,\n",
    "                    recurrent_initializer='glorot_uniform')(input_sequence)\n",
    "\n",
    "  recurrent_2 = l.GRU(rnn_units2,\n",
    "                      batch_size=batch_size, #in case of stateful\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform')(recurrent)\n",
    "\n",
    "\n",
    "  # Softmax output layer\n",
    "  # Last layer with an output for each places\n",
    "  output = layers.Dense(number_of_places, activation='softmax')(recurrent_2)\n",
    "\n",
    "\n",
    "  # To return the Model, we need to define its inputs and outputs\n",
    "  # In out case, we need to list all the input layers we have defined\n",
    "  inputs = list(feature_inputs.values()) + list(sequence_input.values())\n",
    "\n",
    "  # Return the Model\n",
    "  return tf.keras.Model(inputs=inputs, outputs=output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Get the model and compile it\n",
    "mh.assign_model(create_keras_model())\n",
    "mh.compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "summary() got an unexpected keyword argument 'with_early_stopping'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_6052\\2543525468.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwith_early_stopping\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: summary() got an unexpected keyword argument 'with_early_stopping'"
     ]
    }
   ],
   "source": [
    "mh.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.4798 - sparse_categorical_accuracy: 0.2673 - val_loss: 2.9824 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 2/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.4766 - sparse_categorical_accuracy: 0.2681 - val_loss: 2.9802 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 3/15\n",
      "1622/1622 [==============================] - 20s 13ms/step - loss: 2.4721 - sparse_categorical_accuracy: 0.2702 - val_loss: 2.9894 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 4/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.4651 - sparse_categorical_accuracy: 0.2721 - val_loss: 2.9992 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 5/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.4591 - sparse_categorical_accuracy: 0.2755 - val_loss: 2.9870 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 6/15\n",
      "1622/1622 [==============================] - 20s 13ms/step - loss: 2.4539 - sparse_categorical_accuracy: 0.2755 - val_loss: 2.9855 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 7/15\n",
      "1622/1622 [==============================] - 20s 13ms/step - loss: 2.4502 - sparse_categorical_accuracy: 0.2763 - val_loss: 2.9950 - val_sparse_categorical_accuracy: 0.1395\n",
      "Epoch 8/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.4421 - sparse_categorical_accuracy: 0.2774 - val_loss: 3.0008 - val_sparse_categorical_accuracy: 0.1390\n",
      "Epoch 9/15\n",
      "1622/1622 [==============================] - 20s 13ms/step - loss: 2.4316 - sparse_categorical_accuracy: 0.2801 - val_loss: 3.0001 - val_sparse_categorical_accuracy: 0.1383\n",
      "Epoch 10/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.4144 - sparse_categorical_accuracy: 0.2828 - val_loss: 3.0062 - val_sparse_categorical_accuracy: 0.1375\n",
      "Epoch 11/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.3868 - sparse_categorical_accuracy: 0.2897 - val_loss: 3.0140 - val_sparse_categorical_accuracy: 0.1341\n",
      "Epoch 12/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.3546 - sparse_categorical_accuracy: 0.2964 - val_loss: 3.0261 - val_sparse_categorical_accuracy: 0.1318\n",
      "Epoch 13/15\n",
      "1622/1622 [==============================] - 22s 14ms/step - loss: 2.3088 - sparse_categorical_accuracy: 0.3094 - val_loss: 3.0419 - val_sparse_categorical_accuracy: 0.1289\n",
      "Epoch 14/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.2476 - sparse_categorical_accuracy: 0.3264 - val_loss: 3.0378 - val_sparse_categorical_accuracy: 0.1287\n",
      "Epoch 15/15\n",
      "1622/1622 [==============================] - 21s 13ms/step - loss: 2.1785 - sparse_categorical_accuracy: 0.3439 - val_loss: 3.0952 - val_sparse_categorical_accuracy: 0.1244\n"
     ]
    }
   ],
   "source": [
    "mh.set_num_epochs(15)\n",
    "mh.fit_model(with_early_stopping=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/507 [==============================] - 2s 4ms/step - loss: 3.3152 - sparse_categorical_accuracy: 0.1288\n"
     ]
    }
   ],
   "source": [
    "mh.evaluate_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected the accuracy of the model is rather low.\n",
    "But more importantly is how this centralized model compares to the federally trained model.\n",
    "After 15 rounds on flower, the server reported an accuracy of approximately 0.1248.\n",
    "This centralized model achieved 0.1288 with the same amount of epochs.\n",
    "Thus, it can be concluded that the federal approach does not lose much accuracy compared to a centralized approach.\n",
    "The main difference is going to be how long it takes.\n",
    "Flower took roughly 55min to finish 15 rounds of training with two Raspberry PI 4s.\n",
    "The centralized model took around 5min.\n",
    "It is difficult to predict the time difference when larger sets of data and more federated clients are used."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
