{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "NYC_FL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01ekVSe4McOZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Revisiting the NYC Taxi DataSet Model Architecture Part 3\n",
    "\n",
    "In this notebook, the model architecture is being changed in order to understand the correlation between the model architecture and the prediction quality.\n",
    "This model uses sequences of locations as inputs for the GRU network component.\n",
    "That component consists of two GRU layers which are then directly going in a Dense Layer with SoftMax activation to obtain the logits.\n",
    "The deep learning problem can thus be described as follows:\n",
    "Predict the (N+1)th location a history of prior locations in form a sequence of N locations.\n",
    "This model is also based on the changed network architecture from Part 1.\n",
    "As a result, it only predicts the relevant (N+1)th location and not all next locations for every sequence element like it was in the original architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O0AtRRZwKfnz",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "outputId": "ec8f53e1-bede-41f7-a6a1-2bf8249bbf6b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import import_ipynb"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model_helper.ipynb\n"
     ]
    }
   ],
   "source": [
    "from model_helper import ModelHelper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRSBBlWyLG9h",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EiraMJg9uOb9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "outputId": "bd845c7d-9072-46d5-ef12-b26e94566280",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df = pd.read_csv(\"./ma_results/trips_with_zones_final.csv\")\n",
    "df = df.head(10000000)\n",
    "df.head(10)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                          medallion  pickup_week_day  pickup_hour  pickup_day  \\\n0  00005007A9F30E289E760362F69E4EAD                1            0           1   \n1  00005007A9F30E289E760362F69E4EAD                1            0           1   \n2  00005007A9F30E289E760362F69E4EAD                1            0           1   \n3  00005007A9F30E289E760362F69E4EAD                1            1           1   \n4  00005007A9F30E289E760362F69E4EAD                1            1           1   \n5  00005007A9F30E289E760362F69E4EAD                1            1           1   \n6  00005007A9F30E289E760362F69E4EAD                1            2           1   \n7  00005007A9F30E289E760362F69E4EAD                1            2           1   \n8  00005007A9F30E289E760362F69E4EAD                1            2           1   \n9  00005007A9F30E289E760362F69E4EAD                1            3           1   \n\n   pickup_month  dropoff_week_day  dropoff_hour  dropoff_day  dropoff_month  \\\n0             1                 1             0            1              1   \n1             1                 1             0            1              1   \n2             1                 1             1            1              1   \n3             1                 1             1            1              1   \n4             1                 1             1            1              1   \n5             1                 1             2            1              1   \n6             1                 1             2            1              1   \n7             1                 1             2            1              1   \n8             1                 1             3            1              1   \n9             1                 1             3            1              1   \n\n   pickup_location_id  dropoff_location_id  \n0               162.0                262.0  \n1               262.0                239.0  \n2               239.0                236.0  \n3               236.0                 41.0  \n4                41.0                211.0  \n5               211.0                238.0  \n6               238.0                142.0  \n7               142.0                263.0  \n8               263.0                 48.0  \n9                48.0                246.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>medallion</th>\n      <th>pickup_week_day</th>\n      <th>pickup_hour</th>\n      <th>pickup_day</th>\n      <th>pickup_month</th>\n      <th>dropoff_week_day</th>\n      <th>dropoff_hour</th>\n      <th>dropoff_day</th>\n      <th>dropoff_month</th>\n      <th>pickup_location_id</th>\n      <th>dropoff_location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>162.0</td>\n      <td>262.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>262.0</td>\n      <td>239.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>239.0</td>\n      <td>236.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>236.0</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>41.0</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>211.0</td>\n      <td>238.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>238.0</td>\n      <td>142.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>142.0</td>\n      <td>263.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>263.0</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>48.0</td>\n      <td>246.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ggIfgQxKuOcC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "4a248d3b-8b73-4f2b-d7f3-8f9bcaaedbd6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Check dtypes of the attributes\n",
    "df.dtypes"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "medallion               object\npickup_week_day          int64\npickup_hour              int64\npickup_day               int64\npickup_month             int64\ndropoff_week_day         int64\ndropoff_hour             int64\ndropoff_day              int64\ndropoff_month            int64\npickup_location_id     float64\ndropoff_location_id    float64\ndtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Drop the medallion, it is not needed for this example\n",
    "df.drop(['medallion'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ep1BmXDVPxC1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because there are too many taxis (over 9000) it is better to take the 100 taxi with the major number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "pickup_week_day        int32\npickup_hour            int32\npickup_day             int32\npickup_month           int32\ndropoff_week_day       int32\ndropoff_hour           int32\ndropoff_day            int32\ndropoff_month          int32\npickup_location_id     int32\ndropoff_location_id    int32\ndtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast the columns type to int32\n",
    "dictionary = {'pickup_week_day': 'int32', 'pickup_hour': 'int32', 'pickup_day': 'int32', 'pickup_month': 'int32', 'dropoff_week_day': 'int32', 'dropoff_hour': 'int32', 'dropoff_day': 'int32', 'dropoff_month': 'int32', 'pickup_location_id':'int32', 'dropoff_location_id':'int32'}\n",
    "df = df.astype(dictionary, copy=True)\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oH6GxKzwc7K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use the other taxis to create a local test and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHECUQleRxHH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we need to create the location sequence for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "mh = ModelHelper(df, 129)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Uzze3vF-R8OZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Call the function\n",
    "mh.df_to_location_sequence()\n",
    "\n",
    "print(mh.df)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            index  location_id  day  month  hour_sin      hour_cos  \\\n",
      "0               0          162    1      1  0.000000  1.000000e+00   \n",
      "1              12          230    1      1  0.707107  7.071068e-01   \n",
      "2              13          125    1      1  0.707107  7.071068e-01   \n",
      "3              15           48    1      1  0.866025  5.000000e-01   \n",
      "4              18          170    1      1  1.000000  6.123234e-17   \n",
      "...           ...          ...  ...    ...       ...           ...   \n",
      "13731996  7284341          161   26      1 -0.500000 -8.660254e-01   \n",
      "13731997  7284341          161   26      1 -0.500000 -8.660254e-01   \n",
      "13731998  7284342          132   26      1 -0.707107 -7.071068e-01   \n",
      "13731999  7284343          141   26      1 -0.866025 -5.000000e-01   \n",
      "13732000  7284344          141   26      1 -0.866025 -5.000000e-01   \n",
      "\n",
      "          week_day_sin  week_day_cos  weekend  \n",
      "0             0.781831      0.623490        0  \n",
      "1             0.781831      0.623490        0  \n",
      "2             0.781831      0.623490        0  \n",
      "3             0.781831      0.623490        0  \n",
      "4             0.781831      0.623490        0  \n",
      "...                ...           ...      ...  \n",
      "13731996     -0.974928     -0.222521        1  \n",
      "13731997     -0.974928     -0.222521        1  \n",
      "13731998     -0.974928     -0.222521        1  \n",
      "13731999     -0.974928     -0.222521        1  \n",
      "13732000     -0.974928     -0.222521        1  \n",
      "\n",
      "[13732001 rows x 9 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YbQmLj9kSYqp",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "07af026d-8765-4323-8204-953df7b1eccc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "mh.train_val_test_split()\n",
    "print(len(mh.df_train), 'train examples')\n",
    "print(len(mh.df_val), 'validation examples')\n",
    "print(len(mh.df_test), 'test examples')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788480 train examples\n",
      "2197120 validation examples\n",
      "2746401 test examples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ltjLgzdf1LYY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "mh.split_data()\n",
    "mh.list_test[0]"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "            index  location_id  day  month  hour_sin  hour_cos  week_day_sin  \\\n10985600  5283998          246    4      1 -0.866025  0.500000     -0.433884   \n10985601  5283999          107    4      1 -0.707107  0.707107     -0.433884   \n10985602  5284000          142    4      1 -0.707107  0.707107     -0.433884   \n10985603  5284001           48    4      1 -0.500000  0.866025     -0.433884   \n10985604  5284001           48    4      1 -0.500000  0.866025     -0.433884   \n...           ...          ...  ...    ...       ...       ...           ...   \n10985724  5284091          234    7      1  0.000000  1.000000      0.000000   \n10985725  5284092          162    7      1  0.258819  0.965926      0.000000   \n10985726  5284093          142    7      1  0.500000  0.866025      0.000000   \n10985727  5284093          142    7      1  0.500000  0.866025      0.000000   \n10985728  5284094          239    7      1  0.500000  0.866025      0.000000   \n\n          week_day_cos  weekend  \n10985600     -0.900969        0  \n10985601     -0.900969        0  \n10985602     -0.900969        0  \n10985603     -0.900969        0  \n10985604     -0.900969        0  \n...                ...      ...  \n10985724      1.000000        0  \n10985725      1.000000        0  \n10985726      1.000000        0  \n10985727      1.000000        0  \n10985728      1.000000        0  \n\n[129 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>location_id</th>\n      <th>day</th>\n      <th>month</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10985600</th>\n      <td>5283998</td>\n      <td>246</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985601</th>\n      <td>5283999</td>\n      <td>107</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-0.707107</td>\n      <td>0.707107</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985602</th>\n      <td>5284000</td>\n      <td>142</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-0.707107</td>\n      <td>0.707107</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985603</th>\n      <td>5284001</td>\n      <td>48</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985604</th>\n      <td>5284001</td>\n      <td>48</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-0.500000</td>\n      <td>0.866025</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10985724</th>\n      <td>5284091</td>\n      <td>234</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985725</th>\n      <td>5284092</td>\n      <td>162</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0.258819</td>\n      <td>0.965926</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985726</th>\n      <td>5284093</td>\n      <td>142</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985727</th>\n      <td>5284093</td>\n      <td>142</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10985728</th>\n      <td>5284094</td>\n      <td>239</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>129 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sEMnEoqY9CAv",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "outputId": "37048dd7-05ce-4780-fda7-70351e948503",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "mh.set_batch_size(128)\n",
    "mh.create_batch_dataset()\n",
    "mh.test_dataset"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset shapes: ({start_place: (128, 128), start_hour_sin: (128, 128), start_hour_cos: (128, 128), weekend: (128, 128), week_day_sin: (128, 128), week_day_cos: (128, 128), end_hour_sin: (128,), end_hour_cos: (128,), end_weekend: (128,), end_week_day_sin: (128,), end_week_day_cos: (128,)}, (128,)), types: ({start_place: tf.int32, start_hour_sin: tf.float64, start_hour_cos: tf.float64, weekend: tf.int32, week_day_sin: tf.float64, week_day_cos: tf.float64, end_hour_sin: tf.float64, end_hour_cos: tf.float64, end_weekend: tf.int32, end_week_day_sin: tf.float64, end_week_day_cos: tf.float64}, tf.int32)>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "mh.set_target_column_name('location_id')\n",
    "mh.set_vocab_size()\n",
    "mh.set_numerical_column_names(['start_hour_sin', 'start_hour_cos', 'weekend', 'week_day'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bHDBtZVwYXWT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 256\n",
    "\n",
    "# Create a model\n",
    "def create_model():\n",
    "  N = mh.total_window_length\n",
    "  batch_size = mh.batch_size\n",
    "  number_of_places = mh.vocab_size\n",
    "\n",
    "\t# Shortcut to the layers package\n",
    "  l = tf.keras.layers\n",
    "\n",
    "   # Declare the dictionary for the places sequence as before\n",
    "  sequence_input = {\n",
    "      'start_place': tf.keras.Input((N-1,), batch_size=batch_size, dtype=tf.dtypes.int32, name='start_place') # add batch_size=batch_size in case of stateful GRU\n",
    "  }\n",
    "\n",
    "  # Handling the categorical feature sequence using one-hot\n",
    "  places_one_hot = feature_column.sequence_categorical_column_with_vocabulary_list(\n",
    "      'start_place', [i for i in range(number_of_places)])\n",
    "\n",
    "  # Embed the one-hot encoding\n",
    "  places_embed = feature_column.embedding_column(places_one_hot, embedding_dim)\n",
    "\n",
    "  # With an input sequence we can't use the DenseFeature layer, we need to use the SequenceFeatures\n",
    "  sequence_features, sequence_length = tf.keras.experimental.SequenceFeatures(places_embed)(sequence_input)\n",
    "\n",
    "  sequence_features = tf.ensure_shape(sequence_features, (batch_size, N-1, sequence_features.shape[2]))\n",
    "\n",
    "  # Rnn\n",
    "  recurrent = l.GRU(rnn_units,\n",
    "                        batch_size=batch_size, #in case of stateful\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform')(sequence_features)\n",
    "\n",
    "  recurrent_2 = l.GRU(64,\n",
    "                        batch_size=batch_size, #in case of stateful\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform')(recurrent)\n",
    "\n",
    "\t# Last layer with an output for each places\n",
    "  dense_1 = layers.Dense(number_of_places)(recurrent_2)\n",
    "\n",
    "\t# Softmax output layer\n",
    "  output = l.Softmax()(dense_1)\n",
    "\n",
    "\t# To return the Model, we need to define its inputs and outputs\n",
    "\t# In out case, we need to list all the input layers we have defined\n",
    "  inputs = list(sequence_input.values())\n",
    "\n",
    "\t# Return the Model\n",
    "  return tf.keras.Model(inputs=inputs, outputs=output)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Get the model and compile it\n",
    "mh.assign_model(create_model())\n",
    "mh.compile_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLTlfunoO0Yd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:543: UserWarning: Input dict contained keys ['start_hour_sin', 'start_hour_cos', 'weekend', 'week_day_sin', 'week_day_cos', 'end_hour_sin', 'end_hour_cos', 'end_weekend', 'end_week_day_sin', 'end_week_day_cos'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532/532 [==============================] - 244s 459ms/step - loss: 4.1860 - sparse_categorical_accuracy: 0.0453 - val_loss: 4.0380 - val_sparse_categorical_accuracy: 0.0801\n",
      "Epoch 2/10\n",
      "532/532 [==============================] - 231s 434ms/step - loss: 3.9600 - sparse_categorical_accuracy: 0.1225 - val_loss: 3.7722 - val_sparse_categorical_accuracy: 0.2139\n",
      "Epoch 3/10\n",
      "532/532 [==============================] - 224s 421ms/step - loss: 3.8242 - sparse_categorical_accuracy: 0.1842 - val_loss: 3.6407 - val_sparse_categorical_accuracy: 0.2492\n",
      "Epoch 4/10\n",
      "532/532 [==============================] - 226s 426ms/step - loss: 3.7530 - sparse_categorical_accuracy: 0.2050 - val_loss: 3.5722 - val_sparse_categorical_accuracy: 0.2721\n",
      "Epoch 5/10\n",
      "532/532 [==============================] - 230s 433ms/step - loss: 3.7033 - sparse_categorical_accuracy: 0.2158 - val_loss: 3.5373 - val_sparse_categorical_accuracy: 0.2798\n",
      "Epoch 6/10\n",
      "532/532 [==============================] - 231s 435ms/step - loss: 3.6665 - sparse_categorical_accuracy: 0.2200 - val_loss: 3.5171 - val_sparse_categorical_accuracy: 0.2835\n",
      "Epoch 7/10\n",
      "532/532 [==============================] - 228s 428ms/step - loss: 3.6316 - sparse_categorical_accuracy: 0.2237 - val_loss: 3.5082 - val_sparse_categorical_accuracy: 0.2844\n",
      "Epoch 8/10\n",
      "532/532 [==============================] - 225s 422ms/step - loss: 3.5953 - sparse_categorical_accuracy: 0.2262 - val_loss: 3.5053 - val_sparse_categorical_accuracy: 0.2840\n",
      "Epoch 9/10\n",
      "532/532 [==============================] - 219s 412ms/step - loss: 3.5560 - sparse_categorical_accuracy: 0.2292 - val_loss: 3.5096 - val_sparse_categorical_accuracy: 0.2838\n",
      "Epoch 10/10\n",
      "532/532 [==============================] - ETA: 0s - loss: 3.5119 - sparse_categorical_accuracy: 0.2323Restoring model weights from the end of the best epoch.\n",
      "532/532 [==============================] - 214s 402ms/step - loss: 3.5119 - sparse_categorical_accuracy: 0.2323 - val_loss: 3.5177 - val_sparse_categorical_accuracy: 0.2834\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "mh.set_num_epochs(10)\n",
    "mh.fit_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 18s 108ms/step - loss: 3.5253 - sparse_categorical_accuracy: 0.2797\n"
     ]
    }
   ],
   "source": [
    "mh.evaluate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "start_place (InputLayer)     [(128, 128)]              0         \n",
      "_________________________________________________________________\n",
      "sequence_features (SequenceF ((None, None, 256), (None 67584     \n",
      "_________________________________________________________________\n",
      "tf_op_layer_EnsureShape (Ten [(128, 128, 256)]         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, 128, 256)           394752    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (128, 64)                 61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, 264)                17160     \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (128, 264)                0         \n",
      "=================================================================\n",
      "Total params: 541,320\n",
      "Trainable params: 541,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mh.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits\n",
      "Shape :  (21248, 264)\n",
      "Example [0] :  [5.30494784e-04 1.64323923e-04 6.92517332e-08 4.56704402e-06\n",
      " 1.03461242e-03 2.55441762e-07 4.84571387e-07 1.07182667e-03\n",
      " 9.85115457e-06 3.44731689e-06 1.59870760e-05 4.05478750e-06\n",
      " 1.82899064e-04 4.08092467e-03 1.87336598e-04 2.47297976e-06\n",
      " 2.86690835e-07 7.24800921e-05 5.83591791e-05 2.76320662e-07\n",
      " 8.42785482e-07 1.09552157e-05 2.28656427e-05 6.63835579e-07\n",
      " 3.96374753e-03 2.71883589e-04 1.37602219e-05 4.18450554e-08\n",
      " 1.30673854e-07 1.92502848e-05 2.39567814e-08 1.13823153e-05\n",
      " 1.01036028e-06 6.29448099e-04 1.15810490e-05 2.31947683e-06\n",
      " 5.33016864e-05 8.76752893e-05 4.92527943e-06 1.10343180e-05\n",
      " 1.32319212e-04 5.08598331e-03 1.04681996e-03 1.33284358e-02\n",
      " 9.71893996e-07 7.85556971e-04 1.07148628e-06 1.32435935e-05\n",
      " 5.54284304e-02 3.17069382e-04 1.13848895e-02 9.49335390e-06\n",
      " 2.81587680e-04 1.34139727e-05 2.12952837e-05 6.85843042e-06\n",
      " 7.39434745e-06 3.85819277e-07 2.08405891e-06 4.52713834e-07\n",
      " 7.84942858e-06 1.57606759e-04 8.57097402e-05 3.48657250e-06\n",
      " 3.14261541e-08 2.91281958e-05 1.82384625e-04 4.09096247e-05\n",
      " 2.49506328e-02 2.05153465e-05 8.47679257e-05 2.79854339e-06\n",
      " 7.19765649e-06 1.45815320e-05 1.77075015e-03 6.60472084e-03\n",
      " 4.54482688e-05 6.25620032e-06 4.83038002e-06 8.07097275e-03\n",
      " 7.35543581e-05 7.80686321e-07 1.07273365e-04 9.91089400e-05\n",
      " 1.13365450e-05 8.35741776e-06 2.39958149e-06 3.39072524e-03\n",
      " 7.66284473e-04 5.43494461e-05 1.28591666e-02 8.56810857e-06\n",
      " 2.92649638e-05 2.15924229e-05 8.58810290e-06 2.08673009e-04\n",
      " 9.87939893e-06 5.50045515e-04 3.70974544e-06 7.73591040e-08\n",
      " 2.57586055e-02 5.77840729e-06 7.05156481e-06 3.11047295e-08\n",
      " 7.18272801e-08 1.30727443e-07 1.31329318e-04 1.36468140e-02\n",
      " 1.51499620e-07 5.81736046e-08 1.68006636e-07 4.02788558e-08\n",
      " 6.01546490e-04 5.19478507e-03 8.70392658e-03 5.14053454e-06\n",
      " 1.22331642e-03 6.01404437e-08 1.24540720e-05 1.00313264e-04\n",
      " 1.05351910e-06 1.35609662e-05 1.32881123e-05 1.01196638e-05\n",
      " 2.27059581e-06 1.32227386e-03 3.36456906e-05 3.65255721e-04\n",
      " 3.99261080e-05 1.80536255e-04 4.15046270e-05 1.65983511e-06\n",
      " 2.09830166e-03 1.44025298e-05 1.83948964e-06 1.38257419e-05\n",
      " 1.84466589e-05 3.85669572e-03 3.51576344e-03 3.72912723e-06\n",
      " 8.53496697e-03 2.93385517e-02 6.21322617e-02 2.32174769e-02\n",
      " 3.49509949e-03 6.24226697e-04 1.89775019e-04 4.90619459e-06\n",
      " 5.13677159e-03 6.84708141e-07 6.44803777e-06 3.97302350e-03\n",
      " 7.77002657e-04 2.08785768e-05 2.28093413e-07 2.81972893e-06\n",
      " 1.25341771e-07 8.33197992e-05 8.09095055e-03 3.54869444e-05\n",
      " 9.45299689e-05 1.13606490e-01 4.38466482e-02 6.80527240e-02\n",
      " 2.40385514e-02 1.49350271e-05 6.58711419e-03 7.38565086e-06\n",
      " 7.19954842e-05 3.71286187e-05 2.20892932e-02 2.80159838e-06\n",
      " 6.68054236e-06 9.34764830e-05 1.70846633e-05 9.32047470e-08\n",
      " 1.09971687e-07 4.88707610e-06 1.18128150e-06 4.77919297e-04\n",
      " 8.30576766e-07 4.58494993e-04 2.33574883e-05 2.73310798e-06\n",
      " 3.71140527e-06 6.67901304e-06 2.16133185e-02 7.56148069e-08\n",
      " 2.35983171e-05 2.10294005e-04 1.85305871e-05 1.51500296e-06\n",
      " 1.87775868e-06 4.90283855e-05 1.09460352e-05 1.61318058e-05\n",
      " 2.36135704e-04 3.60543454e-05 2.97966362e-05 9.52622869e-08\n",
      " 1.60410098e-04 2.06979394e-06 1.38116084e-04 9.61620117e-06\n",
      " 7.81151428e-08 9.45005780e-08 1.41051214e-06 9.12071300e-06\n",
      " 1.17860172e-05 5.72826422e-04 2.04333555e-05 3.08703049e-03\n",
      " 3.52982488e-06 1.19896149e-05 1.35101243e-06 4.77166441e-06\n",
      " 3.90627861e-07 3.27502712e-05 3.61621414e-06 5.83677229e-06\n",
      " 2.72073725e-04 5.36174980e-08 1.48141794e-07 2.54830462e-04\n",
      " 7.43180630e-04 6.95452327e-05 5.69407304e-04 9.17397119e-06\n",
      " 5.03519805e-05 1.11843664e-02 3.90609875e-02 3.82541493e-03\n",
      " 3.70804628e-04 3.24871228e-03 1.79375149e-02 3.57506951e-06\n",
      " 4.07542363e-02 4.76024635e-02 4.07111198e-02 6.13477491e-02\n",
      " 1.81982214e-05 7.61517867e-06 3.24455368e-06 3.77881713e-03\n",
      " 3.78297642e-03 5.99603993e-08 2.17689015e-02 5.35125255e-05\n",
      " 1.16118154e-05 7.76225189e-03 8.70360236e-06 1.51407193e-07\n",
      " 3.46766456e-06 3.02541885e-08 4.27415216e-06 3.06997972e-04\n",
      " 3.02013534e-04 3.01258242e-05 1.52591783e-05 3.51548515e-05\n",
      " 2.25318596e-04 7.79034977e-04 6.42536860e-03 7.47106876e-03]\n",
      "predictions\n",
      "Shape :  (21248, 264)\n",
      "Example [0] :  tf.Tensor(\n",
      "[0.00377527 0.00377389 0.00377327 0.00377328 0.00377717 0.00377327\n",
      " 0.00377327 0.00377731 0.0037733  0.00377328 0.00377333 0.00377328\n",
      " 0.00377396 0.0037887  0.00377397 0.00377328 0.00377327 0.00377354\n",
      " 0.00377349 0.00377327 0.00377327 0.00377331 0.00377335 0.00377327\n",
      " 0.00378825 0.00377429 0.00377332 0.00377327 0.00377327 0.00377334\n",
      " 0.00377327 0.00377331 0.00377327 0.00377564 0.00377331 0.00377328\n",
      " 0.00377347 0.0037736  0.00377329 0.00377331 0.00377377 0.00379251\n",
      " 0.00377722 0.00382389 0.00377327 0.00377623 0.00377327 0.00377332\n",
      " 0.00398832 0.00377446 0.00381647 0.0037733  0.00377433 0.00377332\n",
      " 0.00377335 0.00377329 0.00377329 0.00377327 0.00377327 0.00377327\n",
      " 0.0037733  0.00377386 0.00377359 0.00377328 0.00377327 0.00377338\n",
      " 0.00377395 0.00377342 0.0038686  0.00377334 0.00377359 0.00377328\n",
      " 0.00377329 0.00377332 0.00377995 0.00379827 0.00377344 0.00377329\n",
      " 0.00377328 0.00380384 0.00377354 0.00377327 0.00377367 0.00377364\n",
      " 0.00377331 0.0037733  0.00377328 0.00378608 0.00377616 0.00377347\n",
      " 0.0038221  0.0037733  0.00377338 0.00377335 0.0037733  0.00377405\n",
      " 0.0037733  0.00377534 0.00377328 0.00377327 0.00387172 0.00377329\n",
      " 0.00377329 0.00377327 0.00377327 0.00377327 0.00377376 0.00382511\n",
      " 0.00377327 0.00377327 0.00377327 0.00377327 0.00377554 0.00379292\n",
      " 0.00380625 0.00377329 0.00377789 0.00377327 0.00377331 0.00377365\n",
      " 0.00377327 0.00377332 0.00377332 0.0037733  0.00377328 0.00377826\n",
      " 0.00377339 0.00377464 0.00377342 0.00377395 0.00377342 0.00377327\n",
      " 0.00378119 0.00377332 0.00377327 0.00377332 0.00377334 0.00378785\n",
      " 0.00378656 0.00377328 0.00380561 0.00388561 0.00401514 0.0038619\n",
      " 0.00378648 0.00377562 0.00377398 0.00377329 0.0037927  0.00377327\n",
      " 0.00377329 0.00378829 0.0037762  0.00377335 0.00377327 0.00377328\n",
      " 0.00377327 0.00377358 0.00380392 0.0037734  0.00377362 0.00422723\n",
      " 0.00394239 0.00403899 0.00386507 0.00377332 0.0037982  0.00377329\n",
      " 0.00377354 0.00377341 0.00385754 0.00377328 0.00377329 0.00377362\n",
      " 0.00377333 0.00377327 0.00377327 0.00377329 0.00377327 0.00377507\n",
      " 0.00377327 0.003775   0.00377335 0.00377328 0.00377328 0.00377329\n",
      " 0.00385571 0.00377327 0.00377336 0.00377406 0.00377334 0.00377327\n",
      " 0.00377327 0.00377345 0.00377331 0.00377333 0.00377416 0.0037734\n",
      " 0.00377338 0.00377327 0.00377387 0.00377327 0.00377379 0.0037733\n",
      " 0.00377327 0.00377327 0.00377327 0.0037733  0.00377331 0.00377543\n",
      " 0.00377334 0.00378493 0.00377328 0.00377331 0.00377327 0.00377328\n",
      " 0.00377327 0.00377339 0.00377328 0.00377329 0.00377429 0.00377327\n",
      " 0.00377327 0.00377423 0.00377607 0.00377353 0.00377542 0.0037733\n",
      " 0.00377346 0.0038157  0.00392357 0.00378773 0.00377467 0.00378554\n",
      " 0.00384156 0.00377328 0.00393022 0.00395723 0.00393005 0.004012\n",
      " 0.00377334 0.0037733  0.00377328 0.00378755 0.00378757 0.00377327\n",
      " 0.00385631 0.00377347 0.00377331 0.00380267 0.0037733  0.00377327\n",
      " 0.00377328 0.00377327 0.00377328 0.00377443 0.00377441 0.00377338\n",
      " 0.00377332 0.0037734  0.00377412 0.00377621 0.00379759 0.00380156], shape=(264,), dtype=float32)\n",
      "predicted_classes\n",
      "Shape :  (21248,)\n",
      "Example [0] :  161\n",
      "actual_values\n",
      "Shape :  (21248,)\n",
      "Example [0] :  239\n",
      "diff\n",
      "Shape :  (21248,)\n",
      "Example [0] :  78\n",
      "Prediction # 0\n",
      "Actual values:  239\n",
      "Predicted values:  161\n",
      "Prediction # 1\n",
      "Actual values:  158\n",
      "Predicted values:  107\n",
      "Prediction # 2\n",
      "Actual values:  100\n",
      "Predicted values:  158\n",
      "Prediction # 3\n",
      "Actual values:  48\n",
      "Predicted values:  234\n",
      "Prediction # 4\n",
      "Actual values:  238\n",
      "Predicted values:  161\n",
      "Prediction # 5\n",
      "Actual values:  90\n",
      "Predicted values:  141\n",
      "Prediction # 6\n",
      "Actual values:  236\n",
      "Predicted values:  13\n",
      "Prediction # 7\n",
      "Actual values:  48\n",
      "Predicted values:  170\n",
      "Prediction # 8\n",
      "Actual values:  229\n",
      "Predicted values:  229\n",
      "Prediction # 9\n",
      "Actual values:  263\n",
      "Predicted values:  263\n",
      "Prediction # 10\n",
      "Actual values:  162\n",
      "Predicted values:  162\n",
      "Prediction # 11\n",
      "Actual values:  144\n",
      "Predicted values:  144\n",
      "Prediction # 12\n",
      "Actual values:  138\n",
      "Predicted values:  211\n",
      "Prediction # 13\n",
      "Actual values:  161\n",
      "Predicted values:  161\n",
      "Prediction # 14\n",
      "Actual values:  113\n",
      "Predicted values:  170\n",
      "Prediction # 15\n",
      "Actual values:  164\n",
      "Predicted values:  163\n",
      "Prediction # 16\n",
      "Actual values:  75\n",
      "Predicted values:  230\n",
      "Prediction # 17\n",
      "Actual values:  162\n",
      "Predicted values:  148\n",
      "Prediction # 18\n",
      "Actual values:  162\n",
      "Predicted values:  263\n",
      "Prediction # 19\n",
      "Actual values:  229\n",
      "Predicted values:  87\n",
      "# correct Predictions :  5943\n",
      "# wrong Predictions :  15305\n",
      "accuracy:  0.2796969126506024\n"
     ]
    }
   ],
   "source": [
    "mh.print_test_prediction_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The assumption proved correct.\n",
    "Using only the location history and no time components at all results in a similar prediction quality.\n",
    "That means that the network can predict the next location on the last locations.\n",
    "\n",
    "Note after evaluating the central model prediction:\n",
    "The behaviour of the model makes sense as it mostly predicts the user to remain in the same area.\n",
    "Thus, time components are irrelevant."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}