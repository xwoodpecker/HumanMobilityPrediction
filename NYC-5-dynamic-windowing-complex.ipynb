{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# STEP 5 - Dynamic Windowing\n",
    "\n",
    "Using a simple model with dynamic windowing resulted in a non-existent prediction accuracy.\n",
    "One possible solution for that, is the simplicity of the model itself.\n",
    "The original work uses a rather complex model with SequenceFeatures and Embedding for the One-Hot-Encoded target features.\n",
    "Next, it is to be verified if using a more complex model leads to the expected prediction quality.\n",
    "If that is not the case, the problem is probably with the windowing itself.\n",
    "It could be that the used functions shuffle the sequences or somehow change the data, so the deep learning network can not detect patterns anymore."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing sequence_stride\n",
    "\n",
    "One assumption why the performance is lacking is the data itself.\n",
    "Maybe using only the data of one taxi to build the sequences is not sufficient.\n",
    "The sliding window function creates many sequences but the data itself is not heterogeneous enough.\n",
    "The test involves using a larger part of the original data and creating less window sequences by using the parameter \"sequence_stride\".\n",
    "This param makes it possible to skip sequences by moving the starting index multiple values ahead.\n",
    "An example follows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def timeseries_dataset_from_array(\n",
    "        data,\n",
    "        targets,\n",
    "        sequence_length,\n",
    "        sequence_stride=1,\n",
    "        sampling_rate=1,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        seed=None,\n",
    "        start_index=None,\n",
    "        end_index=None,\n",
    "):\n",
    "    if start_index:\n",
    "        if start_index < 0:\n",
    "            raise ValueError(\n",
    "                \"`start_index` must be 0 or greater. Received: \"\n",
    "                f\"start_index={start_index}\"\n",
    "            )\n",
    "        if start_index >= len(data):\n",
    "            raise ValueError(\n",
    "                \"`start_index` must be lower than the length of the \"\n",
    "                f\"data. Received: start_index={start_index}, for data \"\n",
    "                f\"of length {len(data)}\"\n",
    "            )\n",
    "    if end_index:\n",
    "        if start_index and end_index <= start_index:\n",
    "            raise ValueError(\n",
    "                \"`end_index` must be higher than `start_index`. \"\n",
    "                f\"Received: start_index={start_index}, and \"\n",
    "                f\"end_index={end_index} \"\n",
    "            )\n",
    "        if end_index >= len(data):\n",
    "            raise ValueError(\n",
    "                \"`end_index` must be lower than the length of the \"\n",
    "                f\"data. Received: end_index={end_index}, for data of \"\n",
    "                f\"length {len(data)}\"\n",
    "            )\n",
    "        if end_index <= 0:\n",
    "            raise ValueError(\n",
    "                \"`end_index` must be higher than 0. \"\n",
    "                f\"Received: end_index={end_index}\"\n",
    "            )\n",
    "\n",
    "    # Validate strides\n",
    "    if sampling_rate <= 0:\n",
    "        raise ValueError(\n",
    "            \"`sampling_rate` must be higher than 0. Received: \"\n",
    "            f\"sampling_rate={sampling_rate}\"\n",
    "        )\n",
    "    if sampling_rate >= len(data):\n",
    "        raise ValueError(\n",
    "            \"`sampling_rate` must be lower than the length of the \"\n",
    "            f\"data. Received: sampling_rate={sampling_rate}, for data \"\n",
    "            f\"of length {len(data)}\"\n",
    "        )\n",
    "    if sequence_stride <= 0:\n",
    "        raise ValueError(\n",
    "            \"`sequence_stride` must be higher than 0. Received: \"\n",
    "            f\"sequence_stride={sequence_stride}\"\n",
    "        )\n",
    "    if sequence_stride >= len(data):\n",
    "        raise ValueError(\n",
    "            \"`sequence_stride` must be lower than the length of the \"\n",
    "            f\"data. Received: sequence_stride={sequence_stride}, for \"\n",
    "            f\"data of length {len(data)}\"\n",
    "        )\n",
    "\n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if end_index is None:\n",
    "        end_index = len(data)\n",
    "\n",
    "    # Determine the lowest dtype to store start positions (to lower memory\n",
    "    # usage).\n",
    "    num_seqs = end_index - start_index - (sequence_length * sampling_rate) + 1\n",
    "    if targets is not None:\n",
    "        num_seqs = min(num_seqs, len(targets))\n",
    "    if num_seqs < 2147483647:\n",
    "        index_dtype = \"int32\"\n",
    "    else:\n",
    "        index_dtype = \"int64\"\n",
    "\n",
    "    # Generate start positions\n",
    "    start_positions = np.arange(0, num_seqs, sequence_stride, dtype=index_dtype)\n",
    "    if shuffle:\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(1e6)\n",
    "        rng = np.random.RandomState(seed)\n",
    "        rng.shuffle(start_positions)\n",
    "\n",
    "    sequence_length = tf.cast(sequence_length, dtype=index_dtype)\n",
    "    sampling_rate = tf.cast(sampling_rate, dtype=index_dtype)\n",
    "\n",
    "    positions_ds = tf.data.Dataset.from_tensors(start_positions).repeat()\n",
    "\n",
    "    # For each initial window position, generates indices of the window elements\n",
    "    indices = tf.data.Dataset.zip(\n",
    "        (tf.data.Dataset.range(len(start_positions)), positions_ds)\n",
    "    ).map(\n",
    "        lambda i, positions: tf.range(\n",
    "            positions[i],\n",
    "            positions[i] + sequence_length * sampling_rate,\n",
    "            sampling_rate,\n",
    "        ),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    dataset = sequences_from_indices(data, indices, start_index, end_index)\n",
    "    if targets is not None:\n",
    "        indices = tf.data.Dataset.zip(\n",
    "            (tf.data.Dataset.range(len(start_positions)), positions_ds)\n",
    "        ).map(\n",
    "            lambda i, positions: positions[i],\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "        )\n",
    "        target_ds = sequences_from_indices(\n",
    "            targets, indices, start_index, end_index\n",
    "        )\n",
    "        dataset = tf.data.Dataset.zip((dataset, target_ds))\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    if batch_size is not None:\n",
    "        if shuffle:\n",
    "            # Shuffle locally at each iteration\n",
    "            dataset = dataset.shuffle(buffer_size=batch_size * 8, seed=seed)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    else:\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def sequences_from_indices(array, indices_ds, start_index, end_index):\n",
    "    dataset = tf.data.Dataset.from_tensors(array[start_index:end_index])\n",
    "    dataset = tf.data.Dataset.zip((dataset.repeat(), indices_ds)).map(\n",
    "        lambda steps, inds: tf.gather(steps, inds),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    )\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate an array with 100 values from 0 to 99.\n",
    "As a result each value corresponds to its own index position.\n",
    "Create sequences of length 9 with a stride of 8 in batches of 4.\n",
    "Each tensor now contains an array of 4 arrays (batch_size).\n",
    "Each respective array has the size 8 (sequence_length).\n",
    "The first value of the first array is 0 (first index).\n",
    "The second array starts with 8 (first index + sequence_stride).\n",
    "The next array always starts with the last index + sequence stride (16,24,32...)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7]\n",
      " [ 8  9 10 11 12 13 14 15]\n",
      " [16 17 18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29 30 31]], shape=(4, 8), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47]\n",
      " [48 49 50 51 52 53 54 55]\n",
      " [56 57 58 59 60 61 62 63]], shape=(4, 8), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[64 65 66 67 68 69 70 71]\n",
      " [72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87]\n",
      " [88 89 90 91 92 93 94 95]], shape=(4, 8), dtype=int32)\n",
      "# Rows over all Batches:  12\n",
      "# Batches:  3\n"
     ]
    }
   ],
   "source": [
    "# sequence_stide is equal to taking chunks\n",
    "s = slice(0, 8)\n",
    "arr = np.array(list(range(0,100)))\n",
    "ds = timeseries_dataset_from_array(data = arr, targets= None, sequence_length=9, sequence_stride=8, shuffle=False, batch_size=4)\n",
    "count = 0\n",
    "for batch in ds:\n",
    "  test = batch[:, s]\n",
    "  print(test)\n",
    "  count += test.shape[0]\n",
    "\n",
    "print('# Rows over all Batches: ', count)\n",
    "print('# Batches: ', len(ds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model_helper.ipynb\n"
     ]
    }
   ],
   "source": [
    "from model_helper import ModelHelper"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/WoodPecker/Documents/Privat/HTW-Master/Sem3/PA/HumanMobilityPredictionMA/ma_results/trips_with_zones_final.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only use the first 10000000 rows."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                          medallion  pickup_week_day  pickup_hour  pickup_day  \\\n0  00005007A9F30E289E760362F69E4EAD                1            0           1   \n1  00005007A9F30E289E760362F69E4EAD                1            0           1   \n2  00005007A9F30E289E760362F69E4EAD                1            0           1   \n3  00005007A9F30E289E760362F69E4EAD                1            1           1   \n4  00005007A9F30E289E760362F69E4EAD                1            1           1   \n5  00005007A9F30E289E760362F69E4EAD                1            1           1   \n6  00005007A9F30E289E760362F69E4EAD                1            2           1   \n7  00005007A9F30E289E760362F69E4EAD                1            2           1   \n8  00005007A9F30E289E760362F69E4EAD                1            2           1   \n9  00005007A9F30E289E760362F69E4EAD                1            3           1   \n\n   pickup_month  dropoff_week_day  dropoff_hour  dropoff_day  dropoff_month  \\\n0             1                 1             0            1              1   \n1             1                 1             0            1              1   \n2             1                 1             1            1              1   \n3             1                 1             1            1              1   \n4             1                 1             1            1              1   \n5             1                 1             2            1              1   \n6             1                 1             2            1              1   \n7             1                 1             2            1              1   \n8             1                 1             3            1              1   \n9             1                 1             3            1              1   \n\n   pickup_location_id  dropoff_location_id  \n0               162.0                262.0  \n1               262.0                239.0  \n2               239.0                236.0  \n3               236.0                 41.0  \n4                41.0                211.0  \n5               211.0                238.0  \n6               238.0                142.0  \n7               142.0                263.0  \n8               263.0                 48.0  \n9                48.0                246.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>medallion</th>\n      <th>pickup_week_day</th>\n      <th>pickup_hour</th>\n      <th>pickup_day</th>\n      <th>pickup_month</th>\n      <th>dropoff_week_day</th>\n      <th>dropoff_hour</th>\n      <th>dropoff_day</th>\n      <th>dropoff_month</th>\n      <th>pickup_location_id</th>\n      <th>dropoff_location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>162.0</td>\n      <td>262.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>262.0</td>\n      <td>239.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>239.0</td>\n      <td>236.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>236.0</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>41.0</td>\n      <td>211.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>211.0</td>\n      <td>238.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>238.0</td>\n      <td>142.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>142.0</td>\n      <td>263.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>263.0</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>00005007A9F30E289E760362F69E4EAD</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>48.0</td>\n      <td>246.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(10000000)\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate the ModelHelper for sequences of length 128."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "mh = ModelHelper(df, 129)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "            index  location_id  day  month  hour_sin      hour_cos  \\\n0               0        162.0    1      1  0.000000  1.000000e+00   \n1              12        230.0    1      1  0.707107  7.071068e-01   \n2              13        125.0    1      1  0.707107  7.071068e-01   \n3              15         48.0    1      1  0.866025  5.000000e-01   \n4              18        170.0    1      1  1.000000  6.123234e-17   \n...           ...          ...  ...    ...       ...           ...   \n13731996  7284341        161.0   26      1 -0.500000 -8.660254e-01   \n13731997  7284341        161.0   26      1 -0.500000 -8.660254e-01   \n13731998  7284342        132.0   26      1 -0.707107 -7.071068e-01   \n13731999  7284343        141.0   26      1 -0.866025 -5.000000e-01   \n13732000  7284344        141.0   26      1 -0.866025 -5.000000e-01   \n\n          week_day_sin  week_day_cos  weekend  \n0             0.781831      0.623490        0  \n1             0.781831      0.623490        0  \n2             0.781831      0.623490        0  \n3             0.781831      0.623490        0  \n4             0.781831      0.623490        0  \n...                ...           ...      ...  \n13731996     -0.974928     -0.222521        1  \n13731997     -0.974928     -0.222521        1  \n13731998     -0.974928     -0.222521        1  \n13731999     -0.974928     -0.222521        1  \n13732000     -0.974928     -0.222521        1  \n\n[13732001 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>location_id</th>\n      <th>day</th>\n      <th>month</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>162.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1.000000e+00</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>230.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.707107</td>\n      <td>7.071068e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>125.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.707107</td>\n      <td>7.071068e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>48.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.866025</td>\n      <td>5.000000e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>170.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>6.123234e-17</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13731996</th>\n      <td>7284341</td>\n      <td>161.0</td>\n      <td>26</td>\n      <td>1</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13731997</th>\n      <td>7284341</td>\n      <td>161.0</td>\n      <td>26</td>\n      <td>1</td>\n      <td>-0.500000</td>\n      <td>-8.660254e-01</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13731998</th>\n      <td>7284342</td>\n      <td>132.0</td>\n      <td>26</td>\n      <td>1</td>\n      <td>-0.707107</td>\n      <td>-7.071068e-01</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13731999</th>\n      <td>7284343</td>\n      <td>141.0</td>\n      <td>26</td>\n      <td>1</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13732000</th>\n      <td>7284344</td>\n      <td>141.0</td>\n      <td>26</td>\n      <td>1</td>\n      <td>-0.866025</td>\n      <td>-5.000000e-01</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>13732001 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.df_to_location_sequence()\n",
    "mh.df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the vocabulary size."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "264"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.set_target_column_name('location_id')\n",
    "mh.set_vocab_size()\n",
    "mh.vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do a basic train/test/val split."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "           index  location_id  day  month  hour_sin      hour_cos  \\\n0              0        162.0    1      1  0.000000  1.000000e+00   \n1             12        230.0    1      1  0.707107  7.071068e-01   \n2             13        125.0    1      1  0.707107  7.071068e-01   \n3             15         48.0    1      1  0.866025  5.000000e-01   \n4             18        170.0    1      1  1.000000  6.123234e-17   \n...          ...          ...  ...    ...       ...           ...   \n8788475  3683176         65.0   30      1 -0.965926  2.588190e-01   \n8788476  3683177        229.0   30      1 -0.965926  2.588190e-01   \n8788477  3683178        160.0   30      1 -0.965926  2.588190e-01   \n8788478  3683179         83.0   30      1 -0.866025  5.000000e-01   \n8788479  3683180        161.0   30      1 -0.866025  5.000000e-01   \n\n         week_day_sin  week_day_cos  weekend  \n0            0.781831      0.623490        0  \n1            0.781831      0.623490        0  \n2            0.781831      0.623490        0  \n3            0.781831      0.623490        0  \n4            0.781831      0.623490        0  \n...               ...           ...      ...  \n8788475      0.974928     -0.222521        0  \n8788476      0.974928     -0.222521        0  \n8788477      0.974928     -0.222521        0  \n8788478      0.974928     -0.222521        0  \n8788479      0.974928     -0.222521        0  \n\n[8788480 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>location_id</th>\n      <th>day</th>\n      <th>month</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>week_day_sin</th>\n      <th>week_day_cos</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>162.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>1.000000e+00</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>230.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.707107</td>\n      <td>7.071068e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>125.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.707107</td>\n      <td>7.071068e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>48.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.866025</td>\n      <td>5.000000e-01</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>170.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>6.123234e-17</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8788475</th>\n      <td>3683176</td>\n      <td>65.0</td>\n      <td>30</td>\n      <td>1</td>\n      <td>-0.965926</td>\n      <td>2.588190e-01</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8788476</th>\n      <td>3683177</td>\n      <td>229.0</td>\n      <td>30</td>\n      <td>1</td>\n      <td>-0.965926</td>\n      <td>2.588190e-01</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8788477</th>\n      <td>3683178</td>\n      <td>160.0</td>\n      <td>30</td>\n      <td>1</td>\n      <td>-0.965926</td>\n      <td>2.588190e-01</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8788478</th>\n      <td>3683179</td>\n      <td>83.0</td>\n      <td>30</td>\n      <td>1</td>\n      <td>-0.866025</td>\n      <td>5.000000e-01</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8788479</th>\n      <td>3683180</td>\n      <td>161.0</td>\n      <td>30</td>\n      <td>1</td>\n      <td>-0.866025</td>\n      <td>5.000000e-01</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8788480 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.basic_split_df()\n",
    "mh.df_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For simplicity, all columns but the location_id are dropped."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "         location_id\n0                162\n1                230\n2                125\n3                 48\n4                170\n...              ...\n8788475           65\n8788476          229\n8788477          160\n8788478           83\n8788479          161\n\n[8788480 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>162</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8788475</th>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>8788476</th>\n      <td>229</td>\n    </tr>\n    <tr>\n      <th>8788477</th>\n      <td>160</td>\n    </tr>\n    <tr>\n      <th>8788478</th>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>8788479</th>\n      <td>161</td>\n    </tr>\n  </tbody>\n</table>\n<p>8788480 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.drop_all_but_target()\n",
    "mh.df_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the \"batch_size\" and instantiate the window generator."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "mh.set_batch_size(BATCH_SIZE)\n",
    "mh.set_window_generator(['location_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sequence_stride is set to 43 in order to create approximately 3 times the amount of sequences as normally (as in using chunks).\n",
    "This is still only 1/43rd of the amount of rows that would be created when using sequence_stride=1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<MapDataset shapes: ((128, 128, 1), (128, 1, 1)), types: (tf.float32, tf.float32)>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_STRIDE = 43\n",
    "mh.make_windowed_dataset(SEQUENCE_STRIDE)\n",
    "mh.train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(TensorSpec(shape=(128, 128, 1), dtype=tf.float32, name=None),\n TensorSpec(shape=(128, 1, 1), dtype=tf.float32, name=None))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh.train_dataset.element_spec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A complex model is defined that uses embedding of the one-hot-encoded target features and SequenceFeature Layers.\n",
    "This is supposed to improve the prediction quality by a lot (see NYC Part 3 Evaluation)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Declare the dictionary for the places sequence as before\n",
    "sequence_input = {\n",
    "  'location_id': tf.keras.Input((mh.sequence_length,), dtype=tf.dtypes.int32, batch_size=BATCH_SIZE, name='location_id')\n",
    "}\n",
    "\n",
    "# Handling the categorical feature sequence using one-hot\n",
    "places_one_hot = feature_column.sequence_categorical_column_with_vocabulary_list(\n",
    "  'location_id', [i for i in range(int(mh.vocab_size))])\n",
    "\n",
    "# Embed the one-hot encoding\n",
    "places_embed = feature_column.embedding_column(places_one_hot, EMBEDDING_DIM)\n",
    "\n",
    "sequence_features, sequence_length = tf.keras.experimental.SequenceFeatures(places_embed)(sequence_input)\n",
    "sequence_features = tf.ensure_shape(sequence_features, (mh.batch_size, mh.sequence_length, EMBEDDING_DIM))\n",
    "\n",
    "gru1 = tf.keras.layers.GRU(256,\n",
    "                           return_sequences=True,\n",
    "                           input_shape=(BATCH_SIZE, mh.sequence_length, EMBEDDING_DIM),\n",
    "                           stateful=True,\n",
    "                           recurrent_initializer='glorot_uniform')(sequence_features)\n",
    "gru2 = tf.keras.layers.GRU(64,\n",
    "                           input_shape=(BATCH_SIZE, mh.sequence_length, EMBEDDING_DIM),\n",
    "                           stateful=True,\n",
    "                           recurrent_initializer='glorot_uniform')(gru1)\n",
    "\n",
    "#drop = tf.keras.layers.Dropout(0.3)(gru2)\n",
    "#dense = tf.keras.layers.Dense(number_of_places, activation='softmax')(drop)\n",
    "\n",
    "dense = tf.keras.layers.Dense(mh.vocab_size)(gru2)\n",
    "output = tf.keras.layers.Softmax()(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=list(sequence_input.values()), outputs=output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1596/1596 [==============================] - 683s 428ms/step - loss: 3.9657 - sparse_categorical_accuracy: 0.1174 - val_loss: 3.7265 - val_sparse_categorical_accuracy: 0.2191\n",
      "Epoch 2/5\n",
      "1596/1596 [==============================] - 633s 397ms/step - loss: 3.8239 - sparse_categorical_accuracy: 0.1863 - val_loss: 3.6426 - val_sparse_categorical_accuracy: 0.2618\n",
      "Epoch 3/5\n",
      "1596/1596 [==============================] - 617s 387ms/step - loss: 3.7938 - sparse_categorical_accuracy: 0.2019 - val_loss: 3.6201 - val_sparse_categorical_accuracy: 0.2690\n",
      "Epoch 4/5\n",
      " 832/1596 [==============>...............] - ETA: 4:37 - loss: 3.9198 - sparse_categorical_accuracy: 0.1570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Temp\\ipykernel_22716\\16564970.py\", line 4, in <module>\n",
      "    mh.fit_model(with_early_stopping=False)\n",
      "  File \"<string>\", line 7, in fit_model\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 103, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1093, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 807, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2829, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1848, in _filtered_call\n",
      "    cancellation_manager=cancellation_manager)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1924, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 550, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\WoodPecker\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\WoodPecker\\AppData\\Local\\Programs\\Python\\Python37\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22716\\16564970.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mmh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.002\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mmh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwith_early_stopping\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\model_helper.ipynb\u001B[0m in \u001B[0;36mfit_model\u001B[1;34m(self, with_early_stopping)\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 103\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1092\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1093\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1094\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 780\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    781\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    806\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 807\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    808\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2828\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2829\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2830\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1847\u001B[0m         \u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcaptured_inputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1848\u001B[1;33m         cancellation_manager=cancellation_manager)\n\u001B[0m\u001B[0;32m   1849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1923\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1924\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1925\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    549\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 550\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    551\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 60\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2098\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2099\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2100\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2100\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2101\u001B[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[1;32m-> 2102\u001B[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001B[0m\u001B[0;32m   2103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2104\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_showtraceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1367\u001B[0m         return FormattedTB.structured_traceback(\n\u001B[1;32m-> 1368\u001B[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0m\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1370\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1267\u001B[0m             return VerboseTB.structured_traceback(\n\u001B[1;32m-> 1268\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1269\u001B[0m             )\n\u001B[0;32m   1270\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'Minimal'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1124\u001B[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[1;32m-> 1125\u001B[1;33m                                                                tb_offset)\n\u001B[0m\u001B[0;32m   1126\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1127\u001B[0m         \u001B[0mcolors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mColors\u001B[0m  \u001B[1;31m# just a shorthand + quicker name lookup\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Privat\\HTW-Master\\Sem3\\PA\\HumanMobilityPredictionMA\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[1;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \u001B[1;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "mh.assign_model(model)\n",
    "mh.set_num_epochs(5)\n",
    "mh.compile_model(optimizer_type=tf.keras.optimizers.Adam, learning_rate=0.002)\n",
    "mh.fit_model(with_early_stopping=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mh.evaluate_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As assumed, when using more heterogeneous data (not only a small interpolated subset), the prediction quality increases.\n",
    "This proves the point that the sliding window data interpolation is only useful in cases of missing data and can not be applied in every case.\n",
    "The prediction quality plummets when it is used to create a large dataset.\n",
    "The interpolated sequencing does not help when the present data does not contain enough patterns for the network to draw conclusions from."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "take = mh.train_dataset.take(1)\n",
    "#predict y\n",
    "#prediction = model.predict(take)\n",
    "\n",
    "data = take.unbatch()\n",
    "X_seq = []\n",
    "Y_true_seq = []\n",
    "\n",
    "for x,y in data:\n",
    "    #print('<y>: ', y.numpy())\n",
    "    X_seq.append(x.numpy()[0][0])\n",
    "    Y_true_seq.append(y.numpy()[0][0])\n",
    "\n",
    "print('X len: ', len(X_seq))\n",
    "print('y Shape: ', y.shape)\n",
    "\n",
    "print('Y_true_seq len: ', len(Y_true_seq))\n",
    "print('X_seq len: ', len(X_seq))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test for SCCE\n",
    "\n",
    "prediction = model.predict(take)\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "scce(Y_true_seq, prediction).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_y_seq = np.array([np.append(x[0], y[0][0]) for x, y in mh.train_dataset])\n",
    "x_y_seq"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(x_y_seq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_loc = []\n",
    "Y = []\n",
    "for x, y in mh.test_dataset:\n",
    "    X_loc.append(x.numpy())\n",
    "    Y.append(y.numpy())\n",
    "\n",
    "X_loc = np.array(X_loc)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X_loc = np.reshape(X_loc, (X_loc.shape[0], X_loc.shape[1], X_loc.shape[2]))\n",
    "Y = np.reshape(Y, (Y.shape[0], Y.shape[1], Y.shape[2]))\n",
    "print('X_loc.shape ', X_loc.shape)\n",
    "print('Y.shape ', Y.shape)\n",
    "X_Y = np.concatenate((X_loc, Y), axis=2)\n",
    "print('X_Y.shape: ', X_Y.shape)\n",
    "X_Y[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The manual evaluation of the results (prediction, scce) does confirm the conclusions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}